Mobile phones offer considerable challenges for game developers, and not least among them is the user interface, which is primarily optimized for number entry rather than for playing games. In fact, due to the limitations one of the most desirable criteria for mobile games has the design of games controlled by a one-button interface. However, this type of interface has only been seen as applicable for casual games, where mastering the interface is de-emphasized. As a number of mobile phones are starting to appear with 3-D accelerometers, game developers have the opportunity to investigate new interface mechanisms. In this article we illustrate how accelerometers provide the possibility of a no-button mobile game. While 3-D accelerometers offer a range of possible interface mechanisms, the one that requires minimal signal processing and no external references is motion, and in particular, tilt, and as such is eminently suitable for mobile phones. In this article we explore a tilt interface for a 3-D graphics first-person driving game titled Tunnel Run, and compare the user experience playing the same game with a traditional phone joypad interface and with a tilt interface in two different modes. The results show that the tilt interface was experienced as fun, and certainly seemed more attractive to players, who said they would not have played this type of game otherwise.
A widely adopted approach to solving constraint satisfaction problems combines systematic tree search with various degrees of constraint propagation for pruning the search space. One common technique to improve the execution efficiency is to add redundant constraints, which are constraints logically implied by others in the problem model. However, some redundant constraints are propagation redundant and hence do not contribute additional propagation information to the constraint solver. Redundant constraints arise naturally in the process of redundant modeling where two models of the same problem are connected and combined through channeling constraints. In this paper, we give general theorems for proving propagation redundancy of one constraint with respect to channeling constraints and constraints in the other model. We illustrate, on problems from CSPlib (http://www.csplib.org), how detecting and removing propagation redundant constraints in redundant modeling can speed up search by several order of magnitudes.
We address the problem of complementing higher-order patterns without repetitions of existential variables. Differently from the first-order case, the complement of a pattern cannot, in general, be described by a pattern, or even by a finite set of patterns. We therefore generalize the simply-typed ?-calculus to include an internal notion of strict function so that we can directly express that a term must depend on a given variable. We show that, in this more expressive calculus, finite sets of patterns without repeated variables are closed under complement and intersection. Our principal application is the transformational approach to negation in higher-order logic programs.
Lists, multisets, and sets are well-known data structures whose usefulness is widely recognized in various areas of computer science. They have been analyzed from an axiomatic point of view with a parametric approach in Dovier et al. [1998], where the relevant unification algorithms have been developed. In this article, we extend these results considering more general constraints, namely, equality and membership constraints and their negative counterparts.
We propose a realizability interpretation of a system for quantier free arithmetic which is equivalent to the fragment of classical arithmetic without nested quantifiers, called here EM1-arithmetic. We interpret classical proofs as interactive learning strategies, namely as processes going through several stages of knowledge and learning by interacting with the �nature,� represented by the standard interpretation of closed atomic formulas, and with each other. We obtain in this way a program extraction method by proof interpretation, which is faithful with respect to proofs, in the sense that it is compositional and that it does not need any translation.
The semantics of most logics of time and probability is given via a probability distribution over threads, where a thread is a structure specifying what will be true at different points in time (in the future). When assessing the probabilities of statements such as �Event a will occur within 5 units of time of event b,� there are many different semantics possible, even when assessing the truth of this statement within a single thread. We introduce the syntax of annotated probabilistic temporal (APT) logic programs and axiomatically introduce the key notion of a frequency function (for the first time) to capture different types of intrathread reasoning, and then provide a semantics for intrathread and interthread reasoning in APT logic programs parameterized by such frequency functions. We develop a comprehensive set of complexity results for consistency checking and entailment in APT logic programs, together with sound and complete algorithms to check consistency and entailment. The basic algorithms use linear programming, but we then show how to substantially and correctly reduce the sizes of these linear programs to yield better computational properties. We describe a real world application we are developing using APT logic programs.
Constraint Handling Rules (CHR) is a committed-choice declarative language that has been originally designed for writing constraint solvers and is nowadays a general purpose language. CHR programs consist of multiheaded guarded rules which allow to rewrite constraints into simpler ones until a solved form is reached. Many empirical evidences suggest that multiple heads augment the expressive power of the language, however no formal result in this direction has been proved, so far. In the first part of this article we analyze the Turing completeness of CHR with respect to the underlying constraint theory. We prove that if the constraint theory is powerful enough then restricting to single head rules does not affect the Turing completeness of the language. On the other hand, differently from the case of the multiheaded language, the single head CHR language is not Turing powerful when the underlying signature (for the constraint theory) does not contain function symbols. In the second part we prove that, no matter which constraint theory is considered, under some reasonable assumptions it is not possible to encode the CHR language (with multi-headed rules) into a single headed language while preserving the semantics of the programs. We also show that, under some stronger assumptions, considering an increasing number of atoms in the head of a rule augments the expressive power of the language. These results provide a formal proof for the claim that multiple heads augment the expressive power of the CHR language.
We propose a purely extensional semantics for higher-order logic programming. In this semantics program predicates denote sets of ordered tuples, and two predicates are equal iff they are equal as sets. Moreover, every program has a unique minimum Herbrand model which is the greatest lower bound of all Herbrand models of the program and the least fixed-point of an immediate consequence operator. We also propose an SLD-resolution proof system which is proven sound and complete with respect to the minimum Herbrand model semantics. In other words, we provide a purely extensional theoretical framework for higher-order logic programming which generalizes the familiar theory of classical (first-order) logic programming.
Recursive loops in a logic program present a challenging problem to the PLP (Probabilistic Logic Programming) framework. On the one hand, they loop forever so that the PLP backward-chaining inferences would never stop. On the other hand, they may generate cyclic influences, which are disallowed in Bayesian networks. Therefore, in existing PLP approaches, logic programs with recursive loops are considered to be problematic and thus are excluded. In this article, we propose a novel solution to this problem by making use of recursive loops to build a stationary dynamic Bayesian network. We introduce a new PLP formalism, called a Bayesian knowledge base. It allows recursive loops and contains logic clauses of the form A ? A1,�,Al, true, Context, Types, which naturally formulate the knowledge that the Ais have direct influences on A in the context Context under the type constraints Types. We use the well-founded model of a logic program to define the direct influence relation and apply SLG-resolution to compute the space of random variables together with their parental connections. This establishes a clear declarative semantics for a Bayesian knowledge base. We view a logic program with recursive loops as a special temporal model, where backward-chaining cycles of the form A? � A? � are interpreted as feedbacks. This extends existing PLP approaches, which mainly aim at (nontemporal) relational models.
We present an effective algorithm for the automatic construction of finite modal transition systems as abstractions of potentially infinite concurrent processes. Modal transition systems are recognized as valuable abstractions for model checking because they allow for the validation as well as refutation of safety and liveness properties. However, the algorithmic construction of finite abstractions from potentially infinite concurrent processes is a missing link that prevents their more widespread usage for model checking of concurrent systems. Our algorithm is a worklist algorithm using concepts from abstract interpretation and operating upon mappings from sets to intervals in order to express simultaneous over- and underapproximations of the multisets of process actions available in a particular state. We obtain a finite abstraction that is 3-valued in both states and transitions and that supports the definition of a 3-valued modal logic for validating as well as refuting properties of systems. The construction is illustrated on a few examples, including the Ingemarsson-Tang-Wong key agreement protocol.
We introduce formal proof systems based on tableau methods for analyzing computations in Answer Set Programming (ASP). Our approach furnishes fine-grained instruments for characterizing operations as well as strategies of ASP solvers. The granularity is detailed enough to capture a variety of propagation and choice methods of algorithms used for ASP solving, also incorporating SAT-based and conflict-driven learning approaches to some extent. This provides us with a uniform setting for identifying and comparing fundamental properties of ASP solving approaches. In particular, we investigate their proof complexities and show that the run-times of best-case computations can vary exponentially between different existing ASP solvers. Apart from providing a framework for comparing ASP solving approaches, our characterizations also contribute to their understanding by pinning down the constitutive atomic operations. Furthermore, our framework is flexible enough to integrate new inference patterns, and so to study their relation to existing ones. To this end, we generalize our approach and provide an extensible basis aiming at a modular incorporation of additional language constructs. This is exemplified by augmenting our basic tableau methods with cardinality constraints and disjunctions.
Logic programming has been introduced as programming in the Horn clause subset of first-order logic. This view breaks down for the negation as failure inference rule. To overcome the problem, one line of research has been to view a logic program as a set of iff-definitions. A second approach was to identify a unique canonical, preferred, or intended model among the models of the program and to appeal to common sense to validate the choice of such model. Another line of research developed the view of logic programming as a nonmonotonic reasoning formalism strongly related to Default Logic and Autoepistemic Logic. These competing approaches have resulted in some confusion about the declarative meaning of logic programming. This paper investigates the problem and proposes an alternative epistemological foundation for the canonical model approach, which is not based on common sense but on a solid mathematical information principle. The thesis is developed that logic programming can be understood as a natural and general logic of inductive definitions. In particular, logic programs with negation represent nonmonotone inductive definitions. It is argued that this thesis results in an alternative justification of the well-founded model as the unique intended model of the logic program. In addition, it equips logic programs with an easy-to-comprehend meaning that corresponds very well with the intuitions of programmers.
The relation between Datalog programs and homomorphism problems, and, between Datalog programs and bounded treewidth structures has been recognized for some time and given much attention recently. Additionally, the essential role of persistent variables (in program expansions) for solving several relevant problems has also started to be observed. In Afrati et al. [2005] the general notion of program persistencies was refined into four notions (two syntactical ones and two semantical ones) and the interrelationship between these four persistency numbers was studied. In the present article (1) we prove undecidability results concerning the semantical notions of persistency number--modulo equivalence, of persistency number and of characteristic integer, (2) we exhibit new classes of programs for which boundedness is undecidable and (3) we prove intractabiltity results concerning the syntactical notions of weak persistency number and of weak characteristic integer.
Many problems in robust control and motion planning can be reduced to either finding a sound approximation of the solution space determined by a set of nonlinear inequalities, or to the "guaranteed tuning problem" as defined by Jaulin and Walter, which amounts to finding a value for some tuning parameter such that a set of inequalities be verified for all the possible values of some perturbation vector. A classical approach to solving these problems, which satisfies the strong soundness requirement, involves some quantifier elimination procedure such as Collins' Cylindrical Algebraic Decomposition symbolic method. Sound numerical methods using interval arithmetic and local consistency enforcement to prune the search space are presented in this article as much faster alternatives for both soundly solving systems of nonlinear inequalities, and addressing the guaranteed tuning problem whenever the perturbation vector has dimension 1. The use of these methods in camera control is investigated, and experiments with the prototype of a declarative modeler to express camera motion using a cinematic language are reported and commented upon.
In this article, we present a declarative propositional temporal logic programming language called TeDiLog that is a combination of the temporal and disjunctive paradigms in logic programming. TeDiLog is, syntactically, a sublanguage of the well-known Propositional Linear-time Temporal Logic (PLTL). TeDiLog allows both eventualities and always-formulas to occur in clause heads and also in clause bodies. To the best of our knowledge, TeDiLog is the first declarative temporal logic programming language that achieves this high degree of expressiveness. We establish the logical foundations of our proposal by formally defining operational and logical semantics for TeDiLog and by proving their equivalence. The operational semantics of TeDiLog relies on a restriction of the invariant-free temporal resolution procedure for PLTL that was introduced by Gaintzarain et al. in [2013]. We define a fixpoint semantics that captures the reverse (bottom-up) operational mechanism and prove its equivalence with the logical semantics. We also provide illustrative examples and comparison with other proposals.
A decision problem is called parameterized if its input is a pair of strings. One of these strings is referred to as a parameter. The following problem is an example of a parameterized decision problem with k serving as a parameter: given a propositional logic program P and a nonnegative integer k, decide whether P has a stable model of size no more than k. Parameterized problems that are NP-complete often become solvable in polynomial time if the parameter is fixed. The problem to decide whether a program P has a stable model of size no more than k, where k is fixed and not a part of input, can be solved in time O(mnk), where m is the size of P and n is the number of atoms in P. Thus, this problem is in the class P. However, algorithms with the running time given by a polynomial of order k are not satisfactory even for relatively small values of k.The key question then is whether significantly better algorithms (with the degree of the polynomial not dependent on k) exist. To tackle it, we use the framework of fixed-parameter complexity. We establish the fixed-parameter complexity for several parameterized decision problems involving models, supported models, and stable models of logic programs. We also establish the fixed-parameter complexity for variants of these problems resulting from restricting attention to definite Horn programs and to purely negative programs. Most of the problems considered in the paper have high fixed-parameter complexity. Thus, it is unlikely that fixing bounds on models (supported models, stable models) will lead to fast algorithms to decide the existence of such models.
As evaluation methods for logic programs have become more sophisticated, the classes of programs for which termination can be guaranteed have expanded. From the perspective of ar set programs that include function symbols, recent work has identified classes for which grounding routines can terminate either on the entire program [Calimeri et al. 2008] or on suitable queries [Baselice et al. 2009]. From the perspective of tabling, it has long been known that a tabling technique called subgoal abstraction provides good termination properties for definite programs [Tamaki and Sato 1986], and this result was recently extended to stratified programs via the class of bounded term-size programs [Riguzzi and Swift 2013]. In this article, we provide a formal definition of tabling with subgoal abstraction resulting in the SLGSA algorithm. Moreover, we discuss a declarative characterization of the queries and programs for which SLGSA terminates. We call this class strongly bounded term-size programs and show its equivalence to programs with finite well-founded models. For normal programs, strongly bounded term-size programs strictly includes the finitely ground programs of Calimeri et al. [2008]. SLGSA has an asymptotic complexity on strongly bounded term-size programs equal to the best known and produces a residual program that can be sent to an answer set programming system. Finally, we describe the implementation of subgoal abstraction within the SLG-WAM of XSB and provide performance results.
Search strategies, that is, strategies that describe how to explore search trees, have raised much interest for constraint satisfaction in recent years. In particular, limited discrepancy search and its variations have been shown to achieve significant improvements in efficiency over depth-first search for some classes of applications.This article reconsiders the implementation of discrepancy search, and of search strategies in general, for applications where the search procedure is dynamic, randomized, and/or generates global cuts (or nogoods) that apply to the remaining search. It illustrates that recomputation-based implementations of discrepancy search are not robust with respect to these extensions and require special care which may increase the memory requirements significantly and destroy the genericity of the implementation.To remedy these limitations, the article proposes a novel implementation scheme based on problem decomposition, which combines the efficiency of the recomputation-based implementations with the robustness of traditional iterative implementations. Experimental results on job-shop scheduling problems illustrate the potential of this new implementation scheme, which, surprisingly, may significantly outperform recomputation-based schemes.
The problem of deciding whether one point in a program is data dependent upon another is fundamental to program analysis and has been widely studied. In this article we consider this problem at the abstraction level of program schemas in which computations occur in the Herbrand domain of terms and predicate symbols, which represent arbitrary predicate functions, are allowed. Given a vertex l in the flowchart of a schema S having only equality (variable copying) assignments, and variables v, w, we show that it is PSPACE-hard to decide whether there exists an execution of a program defined by S in which v holds the initial value of w at at least one occurrence of l on the path of execution, with membership in PSPACE holding provided there is a constant upper bound on the arity of any predicate in S. We also consider the �dual� problem in which v is required to hold the initial value of w at every occurrence of l, for which the analogous results hold. Additionally, the former problem for programs with nondeterministic branching (in effect, free schemas) in which assignments with functions are allowed is proved to be polynomial-time decidable provided a constant upper bound is placed upon the number of occurrences of the concurrency operator in the schemas being considered. This result is promising since many concurrent systems have a relatively small number of threads (concurrent processes), especially when compared with the number of statements they have.
In this paper we present a cut-free sequent calculus, called SeqS, for some standard conditional logics. The calculus uses labels and transition formulas and can be used to prove decidability and space complexity bounds for the respective logics. We also show that these calculi can be the base for uniform proof systems. Moreover, we present CondLean, a theorem prover in Prolog for these calculi.
We present a formal model to represent and solve the unicast/multicast routing problem in networks with quality-of-service (QoS) requirements. To attain this, first we translate the network adapting it to a weighted graph (unicast) or and-or graph (multicast), where the weight on a connector corresponds to the multidimensional cost of sending a packet on the related network link: each component of the weights vector represents a different QoS metric value (e.g., bandwidth). The second step consists in writing this graph as a program in soft-constraint logic programming (SCLP): the engine of this framework is then able to find the best paths/trees by optimizing their costs and solving the constraints imposed on them (e.g. delay ? 40 ms), thus finding a solution to QoS routing problems. C-semiring structures are a convenient tool to model QoS metrics. At last, we provide an implementation of the framework over scale-free networks and we suggest how the performance can be improved. The article highlights the expressivity of SCLP.
Most work in sensor networks tries to maximize network lifetime. However, for many applications the required lifetime is known in advance. Therefore, application quality should rather be maximized for that given time.Levels, the approach presented in this article, is a programming abstraction for energy-aware sensor network applications that helps to meet such a user-defined lifetime goal by deactivating optional functionality. With this programming abstraction, the application developer defines so-called energy levels. Functionality in energy levels is deactivated if the required lifetime cannot be met otherwise. The runtime system uses data about the energy consumption of different levels to compute an optimal level assignment that maximizes each node's quality for the time remaining. As described in this paper, Levels includes a completely distributed coordination algorithm that balances energy level assignments and keeps the application quality of the network roughly constant over time. In this approach, each node computes its schedule based on those of its neighbors. As the evaluation shows, applications using Levels can accurately meet given lifetime goals with only small fluctuations in application quality. In addition, the runtime overhead both for computation and for communication is negligible.
In this roundtable, three professors of parallel programming share their perspective on teaching and learning the computing technique.
This design pattern is an extension of the well-known state pattern [2], which allows an object to change its behavior depending on the internal state of the object. The behavior is defined by events, whose transformation to actions depends on the object state. This pattern introduces a way to manage state actions.
A new mechanism for constructing highly available distributed programs is described. It combines remote procedure call with replication of program modules for fault tolerance.The set of replicas of a module is called a troupe. In a program constructed from troupes, what appears to the programmer as a single inter-module procedure call results in a replicated procedure call. A distributed program constructed in this way will continue to function as long as at least one member of each troupe survives.The semantics of replicated procedure calls and troupes are defined and algorithms are presented that support these semantics.
For years, scientists have dreamed of software programs that, given a very large task, could borrow any kind and number of unused machines available and speed up the job by distributing it around. The need to support some form of adaptive parallelism (AP) is the main property of these programs. As a program may temporarily access machines when their owners do not use them, it is also necessary to return these machines when their owners begin to work again. And as the number of machines allocated to a program expand and contract during its execution, adaptive parallelism allows the program to adjust to this dynamically changing set of machines. For example, a program can start on ten machines, then temporarily use twenty, and finish on five. Numerous projects have attempted to develop such programs. Initial attempts have been undertaken on Local Area Networks (LAN). Most recently, due mainly to the Java language and platform which solve problems such as security, heterogeneity, and portability, several attempts have targeted the Internet. This paper gives a brief overview of some AP systems. Then presents a prototype of an AP system, called ObjectSpace, based on Java Remote Method Invocation (RMI).
Recently, lightweight thread libraries have become a common entity to support concurrent programming on shared memory multiprocessors. However, the disparity between primitives offered by operating systems creates a challenge for those who wish to create portable lightweight thread packages. What should be the interface between the machine-independent and machine-dependent parts of the thread library? We have implemented a portable lightweight thread library on top of Unix on a KSR-1 supercomputer, BBN Butterfly multiprocessor, SGI multiprocessor, Sequent multiprocessor and Sun 3/4 family of uniprocessors. This paper first compares the nature and performance of the OS primitives offered by these machines. We then present procedure-level abstraction that is efficiently implementable on all the architectures and is a sufficient base upon which a user-level thread package can be built.
The client computing platform is moving towards a heterogeneous architecture that combines scalar-oriented CPU cores and throughput-oriented accelerator cores. Recognizing that existing programming models for such heterogeneous platforms are still difficult for most programmers, we advocate a shared virtual memory programming model to improve programmability. In this paper, we focus on performance, and demonstrate that users need not sacrifice performance for programmability. We describe our approaches, experiences, and results in optimizing MYO on a heterogeneous platform consisting of a CPU and an Aubrey Isle accelerator. Our efforts involve the whole system software stack including the OS, runtime, and application.
In this paper, we introduce Bothnia, an extension to the Intel production graphics driver to support a shared virtual memory heterogeneous multithreading programming model. With Bothnia, the Intel graphics device driver can support both the traditional 3D graphics rendering software stack and a new class of heterogeneous multithreaded applications, which can use both IA (Intel Architecture) CPU cores and Intel integrated Graphics and Media Accelerator (GMA) cores in the same virtual address space. We describe the necessary architectural supports in both IA CPU and the GMA cores and present a reference Bothnia implementation. For a set of GPU accelerated media applications on a PC platform with Intel Core 2 Duo CPU and the Intel integrated GMA X3000 running under the Windows XP operating system, Bothnia achieves an average speedup of 3.6x compared to using the GPU as a device, primarily due to Bothnia's support for creation of shared virtual address space between heterogeneous threads of the same application spread on both IA CPU and GMA cores.
Among all classes of parallel programming abstractions, lock-free data structures are considered one of the most scalable and efficient thanks to their fine-grained style of synchronization. However, they are also challenging for developers and tools to verify because of the huge number of possible interleavings that result from finegrained synchronizations. This paper addresses this fundamental problem between performance and verifiability of lock-free data structure implementations. We present TXIT, a system that greatly reduces the set of possible interleavings by inserting transactions into the implementation of a lock-free data structure. We leverage hardware transactional memory support from Intel Haswell processors to enforce these artificial transactions. Evaluation on six popular lock-free data structure libraries shows that TXIT makes it easy to verify lock-free data structures while incurring acceptable runtime overhead. Further analysis shows that two inefficiencies in Haswell are the largest contributors to this overhead.
In this paper, an object logic programming language is proposed that captures all of the basic object-oriented concepts in standard logic programming environment. This paper combines and extends two previously proposed models, namely Conery's technique (1988) which uses first-order logic to model objects including all of the basic object-oriented concepts except inheritance, and the LOGIN language of Ait-Kaci and Nasr (1986) which embeds inheritance into unification using typed logic.In this paper, Conery's proposal is extended by redefining the representation of the objects in a more formal way and by adding inheritance through an extended unification similar to the one proposed by Ait-Kaci and Nasr (1986). We have also changed the type concept of Ait-Kaci and Nasr (1986) by adding types directly to the first-order terms rather than using terms as types. The extended logic language, LPL++, has all the basic object-oriented concepts, namely objects, instances, classes, methods, inheritance, with the availability of update operations on objects in methods. A prototype interpreter also has been developed for the language LPL++.
Technological changes ripple through information technology (IT) development environments. IT professionals must often incorporate these changes into their job or risk obsolescence. This paper looks at the effects of technological change, and focuses on job environment conditions which affect individual performance, health, and well-being by applying person-job fit theory to software developers that have moved to an object-oriented development approach. Heretofore, the literature on person-job fit has viewed its effects statically, disregarding the effects of change. The current research recognizes the dynamics of the IT workplace and investigates the impact of a rapidly changing job environment on individual IT workers by including a comparison of fit at two different points in time. Results indicate that for a change in job environment, individuals whose professional needs match what is supplied by the job fare better in terms of strain and performance. By devoting attention to supplying IT workers who are facing increasing amounts of change with job environment dimensions these workers need, managers are able to direct their efforts toward the job environment dimensions that may improve worker performance and reduce the ill-effects of stress and strain. This, in turn, may have positive effects on overall system development. This study provides insights for managers regarding the pressures felt by software developers moving to a new development environment, and contributes to the person-job fit literature by incorporating a technological change in job environment.
Since their introduction in the late 1960's, planning languages have continued to evolve and to have a growing impact on corporate modeling. In order to better understand how planning languages affect the predevelopment, development, and implementation and use phases of corporate modeling, eight corporate models developed using a planning language and two developed using a general-purpose language were investigated. The findings suggest that planning languages impact corporate modeling in important ways.
This paper provides a brief overview and report on the main out-comes of the software change and evolution (SCE99) workshop held in Los Angeles on May 17, 1999, as part of the International Conference on Software Engineering 1999.The purpose of the workshop was to gather the most active of researchers and practitioners in the field of software evolution and change. The overall conclusion of the workshop was that this is a topic of enormous importance to industry, and there is a growing community of both practitioners and researchers who are working in the field. It would therefore make sense to arrange further workshops to support this expanding community.
While performing a software engineering project, testing is one of the effort intensive activity accounting for up to 50% of total software development cost. To reduce this cost, parallel execution of test cases is a preferred way for developers. Task Parallel Library (TPL) is a powerful and scalable library providing a wide range of methods while facilitating test harnesses. Here, we propose a novel algorithm P-GUI, thereby using TPL. Results of experiment designed on 10 web pages show that proposed algorithm achieved a speedup of 1.4 on average
Cleverly designed software often fails to strictly satisfy its specifications, but instead satisfies them behaviorally, in the sense that they appear to be true under all possible experiments. Hidden algebra extends prior work on abstract data types and algebraic specification [2, 6] to concurrent distributed systems, in a surprisingly simple way that also handles nondeterminism, internal states, and more [4, 3]. Advantages of an algebraic approach include decidability results for problems that are undecidable for more expressive logics, and powerful algorithms like term rewriting and unification, for implementing equational logic tools. Much work in formal methods has addressed code verification, but since empirical studies show that little of software cost comes from coding errors, our approach focuses on behavioral specification and verification at the design level, thus avoiding the distracting complications of programming language semantics.
Data preprocessing is an important activity for discovering behavioral patterns. The analysis of web logs is an essential task for System Administrators to safeguard adequate bandwidth and to maintain server capacity on their business websites. A web Log file represents user activities occurring over a period of time. Web log files offer valuable insight into the effective usage of the web site. It helps maintain an account of the actual usage in a regular working system as compared to the virtual setting of a usability lab. This research paper focuses on the preprocessing techniques implemented on a specially designed Web Sift (WebIS) tool on an IIS web server and also proposes some efficient heuristics and techniques
Despite much research on programming language principles, most often the design of modern languages ignores such principles which results in cumbersome, hard to understand, and error-prone code. We substantiate our claim through a short sampling of the features of some widely used languages and by referring to other criticisms widely publicized in the literature. We argue that a major reason of such an unpleasant state of the art is that programming languages evolve in a way that too much resembles that of natural languages. We advocate a different attitude in programming language design, going back to essentiality and rigorous application of few basic, well-chosen principles.
API usability is a crucial issue in software development. One bottleneck of API usability is insufficient documentation. This study empirically confirmed the inequality of crowdsourced API documentation, which is one of the main sources of API documentation. To manage the inequality, a method for documentation reuse is proposed based on the nature of object-oriented programming language, inheritance. A case study was conducted in Stackoverflow, which is a widely used Q&A site, to study the feasibility of the documentation reuse. Results of the case study indicate that documentation reuse is feasible in improving both the coverage and quality of crowdsourced API documentations.
OCL was introduced as a part of UML in 1997 as a business modeling language by IBM. Ever since its inception, the actual use of OCL in the industry has been almost negligible, even amongst the business application development community, for which it was specifically created. But now with the inception of MDA and related OMG standards the role of OCL is changing. UML 2.0 has introduced new concepts and refined some other including OCL in a way that UML 2.0 is now almost software architectures conformant too. This paper makes an investigation into the recent developments and explores the role of OCL in the current scenario and its future applications.
Business agility is an important challenge while designing an enterprise application. Service oriented architecture is used to combine many outsourced web services to provide value added services to the users with agility. A service registry is maintained to keep track of various web service published by the service providers. The key challenge for the service requester is to pick the best web service among the various functionally equivalent web services in the service registry. This paper describes and analyses various service selection protocols given by the researchers. The approaches are classified into semantic and non-semantic approach. It also proposes a novel technique to look for the best web service based on QoS like reliability, throughput etc. The solution to the problem of selecting the best web service according to the requirements is designed as a fuzzy expert system. This rule based approach of Service registration and lookup is adaptive and responds dynamically to quality of service changes in the web services.
Inner class is a helper class that assists its outer class to perform a specific task. It is declared within the body of outer class. An outer class can contain multiple inner classes in term of breadth and depth. The design principle of inner classes is to have them defined cohesively related to the functionality of outer class. However, method redundancy always renders overheads in inner class design. Eliminating method redundancy is significant because it can reduce the class complexity and enhance the class cohesiveness. This research examines the method redundancy in the inner classes. The author proposes a methodology to rate the complexity of redundant methods in order to reduce class complexity and enhance the inner class design.
The ability of a new technology to reuse legacy systems is very important for its economic success. This paper presents a method for integrating legacy systems within distributed object architectures. The necessary steps required for integration are defined. It is explained how to define object interfaces. A detailed overview of how to implement the wrappers is given. The paper also answers the question which distributed object model is most suitable for legacy integration. Therefore a decision model is defined and the evaluation results are presented.
During the past years, distributed computing approach has become an integral part of many of the software companies. This is because of low cost infrastructure involvement and faster execution of the tasks, sharing of resources, etc. In the year 2009, the Indian Government has established distributed network called as National Knowledge Network (NKN). The main objective of NKN is to connect all of the Indian universities, research institutions, computing labs, digital libraries, countrywide classrooms, etc. In the present paper, a well-known object-oriented Unified Modeling Language (UML) is used to construct a model for the execution of the tasks across a distributed network. Authors have designed a static step topology for the faster execution of tasks. Static and dynamic behaviors of the execution of the tasks are represented through UML class and state diagrams, respectively. For validation of the UML model, the state diagram is converted into a Finite State Machine (FSM) and different test cases are generated to validate the proposed model across distributed network environment.
While performing a software engineering project, testing is one of the effort intensive activity accounting for up to 50% of total software development cost. To reduce this cost, parallel execution of test cases is a preferred way for developers. Task Parallel Library (TPL) is a powerful and scalable library providing a wide range of methods while facilitating test harnesses. Here, we propose a novel algorithm P-GUI, thereby using TPL. Results of experiment designed on 10 web pages show that proposed algorithm achieved a speedup of 1.4 on average.
This paper presents an environment for monitoring software-intensive processes: the Omega environment (Omega stands for On-line Monitoring Environment: General and Adaptable). The environment provides the language Omega/MDL (Monitoring Definition Language) for defining monitoring models as well as a mechanism for the execution of such models Omega/EM (Execution Mechanism). The executing monitoring models (i.e. monitoring systems), observe the subject process and detect deviations between it and an expected behavior, i.e. indicated by the process model instantiation. For monitoring modeling, Omega proposes a novel approach based on fuzzy logic. This approach allows to establish the level of conformance between the process enactment and the process model for different aspects of the process, like progress, cost, structure (order between activities), etc. The use of fuzzy logic enables the system to cope with uncertain and imprecise information.
It is a recommended practice to use overloaded methods in a class for a group of similar operations and functions. However, it is possible that software developers may violate the rule of overloaded methods. In addition, non-overloaded method is used incorrectly sometimes in composing similar functions. This paper presents a technique, using isomorphic graphs, to identify structural similarity between class methods.
When we first write an article, generally speaking, we may not pay a lot of attention to the style. However, after a few more pieces, we will gradually find that these articles need polishing not only in the contents, but also in the styles, so we turn to Struck and White's The Elements of Style for help. Similarly, in the field of computer languages, there have many books (The Elements of Java Style, The Elements of C++ Style, The Elements of UML Style) furnishing a set of rules for writing in a certain language like C++ or Java. To some extent, conforming to style is a symbol of specialty. Consistent style facilitates communication and will be honored by other members in the same team.
Multi-method dispatch in object oriented programs provides additional expressibility, readability and elegance over single dispatch languages. Optimizing multi-method dispatch is a central issue in compilers that support multi-methods. Existing constant time dispatch techniques for multi-methods keep either a lookup table or a lookup tree after compressing the same, the size of which can still be large if compression is not effective. In this paper, we propose a space efficient non-constant time technique (each method address should be computed - rather than being looked up) for multi-method dispatch with single inheritance type hierarchies. The method table containing all the multi-method signatures is the only data structure kept at run time. The table is arranged by sorting on argument position to expedite method search during dispatch. Heuristics is used during method search such that those methods which are not potential candidates are not included in the search. The proposed technique saves space significantly while the dispatch time grew higher compared to existing techniques. When multi-method counts were within practical bounds, the proposed technique was found to offer dispatch time similar to existing techniques.
The goal of this research project is to study techniques and methodologies for execution of Constraint logic programs on parallel and distributed architectures. These models will be applied to implicit and explicit parallelization of complex and irregular symbolic applications, such as those arising in Natural Language Processing, Knowledge-based Systems, and Digital Libraries, and to provide novel frameworks for advanced World-Wide Web programming and coordination of software components.
Our work has studied new language mechanisms for accessing message invocations in message passing based concurrent programming languages. Invocation handling mechanisms in many concurrent languages have significant limitations that make it difficult or costly to solve common programming situations encountered in program visualization, debugging, and scheduling scenarios. We have defined and implemented new such mechanisms within the SR concurrent language and have gained some experience with them.This work has led us to want a cleaner, higher-level way of defining mechanisms for message invocation. We are, therefore, now taking an object-oriented approach. As a step toward that goal, we are currently applying our ideas to Java.Below, we briefly summarize these two areas.
"The Essence of Objects" is an ongoing program of research in programming languages, type systems, and distributed programming at the University of Pennsylvania, supported by the National Science Foundation under Career grant CCR-9701826, Principled Foundations for Programming with Objects. Papers on most of the topics discussed in this outline can be found via http://www.cis.upenn.edu/bcpierce/papers.
An exploratory experiment found that sorting arrays of random integers using Java 8's parallel sort required only 50%-70% of the time taken using the parallel sort of the Parallel Colt library. Factors considered responsible for the performance advantage include the use of a dual-pivot quicksort on locally held data at certain phases of execution and work-stealing by threads, a feature of the fork-join framework. The default performance of Parallel Colt's parallel sort was found to degrade dramatically for small array sizes due to unnecessary thread creation.
We propose a technique for static and dynamic slicing of UML models. For a software architecture specified using UML, we first transform the systems' architectural model into an intermediate representation which we have named Model Dependency Graph(MDG). MDG combines information available in various sequence diagrams along with the relevant information available in class diagrams into an integrated UML model. For a given slicing criterion, our slicing algorithm traverses the constructed MDG to identify the relevant model elements. Our algorithm's novelty lies in its computing a slice based on an integrated UML model as against independently processing separate UML diagrams, and determining the implicit interdependencies among the different model elements distributed across various UML diagrams.
We introduce a methodology, based on symbolic execution, for Concurrent Bounded Model Checking. In our approach, we translate a program into a formula in a disjunctive form. This design enables concurrent verification, with a main thread running symbolic execution, without any constraint solving, to build subformulas, and a set of worker threads running a decision procedure for satisfiability checks. We have implemented this methodology in a tool called JCBMC, the first bounded model checker for Java. JCBMC is built as an extension of Java Pathfinder, an open-source verification platform developed by NASA. JCBMC uses Symbolic PathFinder (SPF) for the symbolic execution, Z3 as the solver and implements concurrency with multi-threading. For evaluation, we compare JCBMC against SPF and the Bounded Model Checker CBMC. The results of the experiments show that we can achieve significant advantages of performance over these two tools.
Class methods are modules in a class that perform a specific behavior. The best software practice in defining a method is to assign a single task for each method. It is always expected that each method should carry out a unique task in its defining class. A series of similar tasks are usually defined by overloaded methods. Such a single-task practice of method definition is seldom imposed on individual software developers who extensively develop user-defined methods. In this research, a method efficiency model is developed with the objective of guiding the software developers in developing an individual cohesive method. Increased cohesion of methods is desirable because it contributes to the enhancement of software maintenance.
Distributed caching system is usually used to alleviate database load in constructing an enterprise web application system. It helps to speed up dynamic web applications. In order to improve the utilization of caching cluster, an appropriate data partitioning and placement scheme is usually applied. This paper proposes a Balanced Partition Scheme (BPS) to solve load imbalance problems and highly skewed data requests in web application. In the BPS, which is based on consistent hash algorithm, the partition and placement schemes are designed respectively to guarantee a system's load balance even when the requests of this system are highly skewed. The range of hash function is divided into several groups equally and those groups will be relocated when caching nodes are overloaded. The implementation and evaluation of the BPS is also presented in this paper. The effectiveness of the BPS has been verified in the simulation experiment and the BPS can successfully solve load imbalance problems when faced with a large number of get/set requests.
Software reuse has become very popular in software development. There are several beneficial aspects of object oriented systems including code reuse, reusability and reusability of testing efforts. Reusable software components are the building blocks that can make a system able to respond quickly to change. This paper presents the hypothesis that the testing effort in object-oriented software can be inherited and reused similar to that of the coding effort. Therefore the testability and maintainability of the object-oriented software can be improved by adapting a reusability approach. In this paper some new metrics namely Reusability of a Class in a System (RCS), Average Degree of Reusability (AR), Specialize class to Base class Reusable Metric (SBRM) have been proposed.
In this paper we describe the results of a recent practitioner survey designed to elicit the opinions as to the challenges and opportunities posed by the application of agile development methods in the field of safety critical systems development. In particular, the survey explored the relationship between three key activities in safety engineering and an agile approach -- namely, safety requirements development, hazard analysis, and safety case development. The results of this survey are presented together with brief discussion of the implications for integration.
Distributed computing has now become one of the most efficient network system configurations to exhibit parallelism in loosely coupled systems. These systems are known for better reliability, availability, scalability and robustness, intended to provide high performance computing in a very efficient manner. The composition of distributed systems consists of multiple autonomous computers that can be geographically dispersed and interconnected with each other to provide optimum resource utilization. The degree of resource utilization is one of the key criteria for evaluating the performance of such systems. We propose a genetic-algorithm-based approach to load optimization in a distributed computing environment. Genetics algorithm has been adapted from the biological gene theory. Since it shows the existence of the fittest chromosome from the sample chromosomes population, it may be used to find the most optimum solution for any problem. This research work demonstrates the implication of genetic algorithms to optimize the overall waiting time for a set of processes to be executed on a set of servers. In order to understand the design complexity, we modeled the proposed approach using UML class and sequence diagrams. The results of the proposed model have been found beneficial when implemented and tested under various test scenarios using C++.
Software variability is the capacity of software to satisfy variant requirements. Component based software engineering and reuseintense software development, such as software product line engineering, demand software components with high variability. Increased variability influences a component's utility as it can be reused in multiple applications. In this paper a review and analysis of variability implementation mechanisms is presented. It builds on earlier work on software variability by providing an analysis and a synthesis. The purpose of this work is to classify the available variability mechanisms in terms of type, scope, and the artefact to be targeted. Examples to illustrate the points under discussion are given in the form of Java code.
Virtual reality technology, which is cyberspace composed of multimedia, is a field of comprehensive technology. It is of three basic feathers, namely, interaction, immersion and imagination so that we have to cope with the need for extremely large data sets, massive amounts of computation, and high-throughput networking. This paper presents an approach for object-oriented data modeling framework of complicated virtual environments. The paper discusses the hierarchical decomposition of objects in virtual environments and reuse of these object data libraries to constitute model of virtual environments. This modeling approach used in the paper makes sure that modeling data can be inherited, modularized, maintained easily so as to control redundant data and reduce the software development time, at the same time, realizes dynamic behaviors of objects to meet the needs of some changes of virtual environments.
In software engineering Experience Factories have been in use for a long time to store and manage experiences from software projects, typically in large organizations. Beside the preservation of quantitative or numerical experiences, e.g., in form of project effort data or data from empirical studies, many experience facto-ries also preserve subjective or qualitative experiences, e.g., in form of observations or lessons learned from the projects. A key issue of experience management is to aggregate these documented experiences into more valuable software patterns. In this article we report about the aggregation (i.e., formalization and generalization) of documented experiences in an experience factory to software patterns. Observations from real-world projects are formalized (i.e., structurally contextualized) into semi-formal experiences and, over time, several similar of these experiences are generalized (i.e., systematically de-contextualized) into software patterns.
Due to the growing complexity of computing systems, and the increasing demand for high availability and reliability of them, adapting software at runtime is becoming more and more important. However, there is not sufficient support for dynamic software adaptation at the level of programming languages. In this paper, we investigate a language feature, namely delegation, to argue that delegation is a favorite choice to deal with dynamic software adaptation. To do that, we present ? calculus, which is an imperative object-based calculus with delegation, to model essential features of languages, with focusing on how to incorporate delegation into programming languages to support dynamic software adaptation. We give the operational semantics of ? calculus. We also state how delegation is used in object extending and method sharing between objects. We conclude that delegation makes dynamic software adaptation simpler and more flexible.
Model checking has been applied quite successfully to hardware verification and shows promise for software verification. The key obstacle is the well-known state explosion problem. This report describes work done by the investigator under NSF support, in particular grants CCR 980-4736 and CCR 941-5496, to ameliorate state explosion.
It is with great pleasure that we introduce the 5th IEEE Interna-tional Workshop on UML and Formal Methods. Already, in its short 5 year history, the workshop has been located across the globe: Japan, Brazil, China, Ireland, and �? this year �? in Paris, France. For its first 3 years it was co-located with the International Conference on Formal Engineering Methods, whilst in the last 2 years it has been part of the International Symposium on Formal Methods. The workshop has a strong tradition of publishing the highest quality accepted papers in either: the NASA journal of �?Innovations in Systems and Software Engineering�?, or the ACM journal �?Software Engineering Notes�? (to whom we have returned this year). The main objective of the workshop has not changed during its lifetime, namely: the building of bridges between informal, semi-formal and formal notations. This objective can be seen in each of the 4 main themes that make up the four sessions of this year�?s workshop: I. UML diagram formalization, II. Dynamic and real-time modeling, III. Transformations, and IV. Patterns and blocks. Across all sessions a wide range of formalisms and tools are pre-sented �? Extended Hierarchical State Transition Matrices and CSP, the SMT solver Yice, MADES UML and metric temporal logic, UML-MARTE and Time Transition Systems, Colored Petri Nets, Behavioural types and Coq, QVT-R and XSLT, EMF Model-ing Operations, ASTD and SysML �? illustrating the breadth and depth of the research being done by our community. We hope that you enjoy reading these papers as much as we have: the bridges are being built and we invite you to cross them.
In a software engineering project, business objects were mapped directly to software and database objects. There was a natural correlation between objects in real world systems and their representation as software objects and database objects. This mapping may serve as an effective model for similar projects.
At present, majority access control models mainly deal with data-protection at the back-end of applications. However, they are not applicable for large and complex multi-user applications. Though Object Technology has turned into one of the mainstream approaches for large and complex applications development, it still lacks a general model of application-level access control. While the existing models of role-based access control could simplify privilege management, they neglect the dynamic features of activated roles. This paper proposes an object-oriented model in Unified Modeling Language supporting application-level access control based on users' roles. In the model, an interface type is provided containing a set of operations as user services, which are authorized to users via their roles. To represent the activated roles, Role-Playing is introduced, and it is modeled as an active class. Every object of Role-Playing runs in particular context, which restrict users' rights dynamically and control users' interaction actively. The model is suitable for multi-user interactive computing and distributed information-processing systems.
Finite State Automata have been extended in a number of ways with varied additional constraints with an objective of modeling varied real life problems. The current paper commonly refers to such extensions as constrained automata. It aims at defining a generic mathematical model for the constrained automata targeted towards interoperability and possible integration amongst them. The paper proposes and demonstrates usage of hyper complex symbols that realizes the objective.
Pattern mining is one of the most pivotal steps in the data mining is pattern mining and it immediately comes after the preprocessing phase of WUM. Pattern discovery deals with the sorted set of data items are presented as part of the sequence. Using this pattern mining, users can recognize the web paths that users commonly follow on a web site easily. This research discovers the most relevant and interesting behavioral patterns by using a Web usage mining process. The server web logs aids as an input to this process. We aim to identify behavioral patterns of the users who typically visit the web sites occasionally. We have employed a method for clustering, based on pattern summaries. We have conducted intense experiments and the results are shown in this paper
This article discusses several uses of the goto statement in modern C/C++ code. The goto statement is considered a harmful statement, which is generally not recommended for use in "high-level" languages. In this discussion, several uses of the goto statement that are helpful in a controlled setting will be presented. These usages are for error handling and jumping out of nested loops.
Graphs are one of the most popular non linear data structures used to represent various data objects. These graphical structures can further be classified into directed and undirected graph representations. For modeling purpose, UML has adopted the phenomenon of directed graphical structures as statechart diagrams, to exhibit dynamic specification of any software or non software system. These diagrams are important as they are used to represent all possible values that an object can retain throughout its life cycle. Three key components are required to change the state of any object namely transition function, action and possible inputs. Statechart diagrams are also useful to determine all possible paths that an object will undergo during its entire life span, while changing its state. Further these paths can be represented with the help of various established graphical modeling techniques like Finite State Automata. The mapping and further analysis of these path structures can be very helpful in determining the correctness of the diagram as well as to highlight the possible deficiencies in the diagram. In the present work, authors have proposed semantics for automatic transformation of UML statechart diagram into its equivalent finite state automata, by taking the advantage of both of the models. Authors have also presented an approach to generate regular grammar for the generated finite state automata. This equivalent grammar can further be useful to generate various test cases, to test UML statechart diagram, against various test conditions. To better illustrate, authors have also presented a case study of an ATM machine and demonstrated that how this approach is helpful to verify the correctness of design
Testing technique-related empirical studies have been performed for 25 years. We have managed to accumulate a fair number of experiments in this time, which might lead us to think that we now could have a sizeable empirically backed body of knowledge (BoK) on testing techniques. However, the experiments in this field have some flaws, and, consequently, the empirical BoK we have on testing techniques is far from solid. In this paper, we use the results of a survey that we did on empirical testing techniques studies to identify and discuss solutions that could lead to the formation of a solid empirical BoK. The solutions are related to two fundamental experimental issues: (1) the rigorousness of the experimental design and analysis, and (2) the need for a series of community-wide agreements to coordinate empirical research and assure that studies ratify and complement each other.
Graphical Processing Units (GPUs) have recently been used to enable parallel application development. The most prominent initiative has been provided by NVIDIA� with the so-called CUDA� architecture, designed to GeForce� graphic cards. However, even with CUDA C-like programming language, parallel codification remains somewhat awkward if compared to sequential codification. The programmer still has to deal with low-level hardware details such as generation and synchronization of threads and GPU tracks and sectors. In this paper, we propose a programmer-friendly interface for CUDA-C programming, in such a way that most hardware details are hidden from the programmer. We show how code readability is improved without undermining parallel execution performance.
Object-oriented programming is still a relatively new technology in the world of web development. Object-oriented programming languages directly support the object notions of classes, inheritance, information hiding, and dynamic binding. In Object-Oriented Programming, a program is seen as comprising a collection of individual modules, or objects, that act on each other. Each of these objects could be seen as an independent program in itself, with a distinct role or responsibility. Object-Oriented Programming provides greater flexibility and easier maintenance across large systems and can sometimes make understanding and analyzing complex procedures a lot easier. This paper presents a comparison of object-oriented programming in software engineering including properties of Java, C++, Eiffel, and Smalltalk languages.
Extreme Programming (XP) is probably the best known and (arguably) the most controversial of the so-called agile software development methodologies. The paper presents the main findings of a small pilot survey about user perceptions of XP.
User satisfaction is recognized as an important contributor to the success of software applications. It is subjective and influenced by several factors that are linked to the non-functional requirements. Although non-functional requirements provide good criteria for selection of web service in Service-Oriented Architecture, specifying them during the discovery process is a difficult task. Dealing with the non-functional requirements that have an inherent ability to conflict is a complex task and modeling them can facilitate analyzing them. The aim of our research work is to propose a framework to improve design stage during web service selection so as to produce minimal conflicts and dependencies between requirements. We argue that the design structure that best supports and embodies the user constraints is the one that best meets a user's needs. Our framework is proposed after a detailed study of the issues and challenges identified by published literature by researchers working on non-functional requirement To exemplify our work we consider a Remote Patient Monitoring System scenario and propose a complete framework that will take the user requirements as input and analyze how they interact using graph transformation rules. The output matrix of dependencies can help the designer to select the most desirable design solution. We make use of simple natural language processing techniques, graph transformation and the aspect oriented paradigm. By integrating the framework into the design phase, it is possible to limit the impact of changes and also to understand in advance the likely interdependencies. conflicts.
Constructing class hierarchies is an important step in object-oriented design, but no formal and effective methods of optimizing class hierarchies were previously established. In this paper, we first divide the relationship between object sets into four categories: inclusion, superposition, separation, and cross. Then the genres of inheritance are discussed from the point of view of object set. Following that, we introduce the concept of maximal uncrossed set used to optimize a class hierarchy. Through finding all of these maximal uncrossed sets, we present the method and steps of constructing a reasonable, clear, and complete class hierarchy. Various representations of inheritance relationship in a class hierarchy diagram and a recursion algorithm to get all the maximal uncrossed sets are also provided in this paper.
Synchronization bugs such as data races and deadlocks make every programmer cringetraditional locks only provide a partial solution, while high-contention locks can easily degrade performance. Maurice Herlihy proposes replacing locks with transactions. He discusses adapting the well-established concept of data base transactions to multicore systems and shared main memory.
Multicore processors dominate the commercial marketplace, with the consequence that almost all computers are now parallel computers. To take maximum advantage of multicore chips, applications and systems should take advantage of that parallelism. As of today, a small fraction of applications do. To improve that situation and to capitalize fully on the power of multicore systems, we need to adopt programming models, parallel algorithms, and programming languages that are appropriate for the multicore world, and to integrate these ideas and tools into the courses that educate the next generation of computer scientists.
As a discipline, we have been discussing parallel programming for years. After all these years, do we know the right language abstractions for parallel programming? Would we recognize the right abstractions if we were to see them? In this article, Todd Mytkowicz and Wolfram Schulte, both from Microsoft Research, ask: Have we been simply biding our time, waiting for our Godot?
In the past, parallel processing was a specialized approach to high-performance computing. Today, we have to rethink the computational cores of algorithmic and data structures applications. In this article we discuss how this process of rethinking can be understood using algorithm engineering.
A new kind of network offers a world of possibilities for moving data and building application architectures centered around common Internet protocols.
Multicore CPUs and GPUs have brought parallel computation within reach of any programmer. How can we put the performance potential of these machines to good use? The contributors of the symposium suggest a number of approaches, among them algorithm engineering, parallel programming languages, compilers that target both SIMD and MIMD architectures, automatic detection and repair of data races, transactional memory, automated performance tuning, and automatic parallelizers. The transition from sequential to parallel computing is now perhaps at the half-way point. Parallel programming will eventually become routine, because advances in hardware, software, and programming tools are simplifying the problems of designing and implementing parallel computations.
Early graphical processing units (GPUs) were designed as high compute density, fixed-function processors ideally crafted to the needs of computer graphics workloads. Today, GPUs are becoming truly first-class computing elements on par with CPUs. Programming GPUs as self-sufficient general-purpose processors is not only hypothetically desirable, but feasible and efficient in practice, opening new opportunities for integration of GPUs in complex software systems.
Finite element methods approximate solutions of partial differential equations by restricting the problem to a finite dimensional function space. In hp adaptive finite element methods, one defines these discrete spaces by choosing different polynomial degrees for the shape functions defined on a locally refined mesh. Although this basic idea is quite simple, its implementation in algorithms and data structures is challenging. It has apparently not been documented in the literature in its most general form. Rather, most existing implementations appear to be for special combinations of finite elements, or for discontinuous Galerkin methods. In this article, we discuss generic data structures and algorithms used in the implementation of hp methods for arbitrary elements, and the complications and pitfalls one encounters. As a consequence, we list the information a description of a finite element has to provide to the generic algorithms for it to be used in an hp context. We support our claim that our reference implementation is efficient using numerical examples in two dimensions and three dimensions, and demonstrate that the hp-specific parts of the program do not dominate the total computing time. This reference implementation is also made available as part of the Open Source deal.II finite element library.
The article presents methods for the computation of all Mathieu functions of integer order, which cover a large range of n and h; previous algorithms were limited to small values of n. The algorithms are given in sufficient detail to enable straightforward implementation. The algorithms can handle a large range of the order n (0-200) and the parameter h (0-4n).
The concern here is with Gauss-type quadrature rules that are exact for a mixture of polynomials and rational functions, the latter being selected so as to simulate poles that may be present in the integrand. The underlying theory is presented as well as methods for constructing such rational Gauss formulae. Relevant computer routines are provided and applied to a number examples, including Fermi-Dirac and Bose-Einstein integrals of interest in solid state physics.
Fortran 77 software implementing the SPG method is introduced. SPG is a nonmonotone projected gradient algorithm for solving large-scale convex-constrained optimization problems. It combines the classical projected gradient method with the spectral gradient choice of steplength and a nonmonotone line-search strategy. The user provides objective function and gradient values, and projections onto the feasible set. Some recent numerical tests are reported on very large location problems, indicating that SPG is substantially more efficient than existing general-purpose software on problems for which projections can be computed efficiently.
The high performance Fortran (HPF) benchmark suite HPFBench is designed for evaluating the HPF language and compilers on scalable architectures. The functionality of the benchmarks covers scientific software library functions and application kernels that reflect the computational structure and communication patterns in fluid dynamic simulations, fundamental physics, and molecular studies in chemistry and biology. The benchmarks are characterized in terms of FLOP count, memory usage, communication pattern, local memory accesses, array allocation mechanism, as well as operation and communication counts per iteration. The benchmarks output performance evaluation metrics in the form of elapsed times, FLOP rates, and communication time breakdowns. We also provide a benchmark guide to aid the choice of subsets of the benchmarks for evaluating particular aspects of an HPF compiler. Furthermore, we report an evaluation of an industry-leading HPF compiler from the Portland Group Inc. using the HPFBench benchmarks on the distributed-memory IBM SP2
ProtoMol is a high-performance framework in C++ for rapid prototyping of novel algorithms for molecular dynamics and related applications. Its flexibility is achieved primarily through the use of inheritance and design patterns (object-oriented programming). Performance is obtained by using templates that enable generation of efficient code for sections critical to performance (generic programming). The framework encapsulates important optimizations that can be used by developers, such as parallelism in the force computation. Its design is based on domain analysis of numerical integrators for molecular dynamics (MD) and of fast solvers for the force computation, particularly due to electrostatic interactions. Several new and efficient algorithms are implemented in ProtoMol. Finally, it is shown that ProtoMol's sequential performance is excellent when compared to a leading MD program, and that it scales well for moderate number of processors. Binaries and source codes for Windows, Linux, Solaris, IRIX, HP-UX, and AIX platforms are available under open source license at http://protomol.sourceforge.net.
In this article we present background, rationale, and a description of the Scalable Parallel Random Number Generators (SPRNG) library. We begin by presenting some methods for parallel pseudorandom number generation. We will focus on methods based on parameterization, meaning that we will not consider splitting methods such as the leap-frog or blocking methods. We describe, in detail, parameterized versions of the following pseudorandom number generators: (1) linear congruential generators, (ii) shift-register generators, and (iii) lagged-Fibonacci generators. We briefly describe the methods, detail some advantages and disadvantages of each method, and recount results from number theory that impact our understanding of their quality of parallel applications. SPRNG was designed around the uniform implementation of different families of parameterized random number generators. We then present a short description of SPRNG. The description contained within this document is meant only to outline the rationale behind and the capabilities of SPRNG. Much more information, including examples and detailed documentation aimed at helping users with putting and using SPRNG on scalable systems is available at http://sprng.cs.fsu.edu. In this description of SPRNG we discuss the random-number generator library as well as the suite of tests of randomness that is an integral part of SPRNG. Random-number tools for parallel Monte Carlo applications must be subjected to classical as well as new types of empirical tests of randomness to eliminate generators that show defects when used in scalable environments.
The SLEIGN2 code is based on the ideas and methods of the original SLEIGN code of 1979. The main purpose of the SLEIGN2 code is to compute eigenvalues and eigenfunctions of regular and singular self-adjoint Sturm-Liouville problems, with both separated and coupled boundary conditions, and to approximate the continuous spectrum in the singular case. The code uses some new algorithms, which we describe, and has a driver program that offers a user-friendly interface. In this paper the algorithms and their implementations are discussed, and the class of problems to which each algorithm applied is identified.
The problem of finding the plane curve of minimal elastic energy with prescribed endpoints and end-directions was solved in 1983 by B. K. P. Horn. Here the solution is discussed, given a very short proof, and extended to include a constant on length.
To face the advent of multicore processors and the ever increasing complexity of hardware architectures, programming models based on DAG parallelism regained popularity in the high performance, scientific computing community. Modern runtime systems offer a programming interface that complies with this paradigm and powerful engines for scheduling the tasks into which the application is decomposed. These tools have already proved their effectiveness on a number of dense linear algebra applications. This article evaluates the usability and effectiveness of runtime systems based on the Sequential Task Flow model for complex applications, namely, sparse matrix multifrontal factorizations that feature extremely irregular workloads, with tasks of different granularities and characteristics and with a variable memory consumption. Most importantly, it shows how this parallel programming model eases the development of complex features that benefit the performance of sparse, direct solvers as well as their memory consumption. We illustrate our discussion with the multifrontal QR factorization running on top of the StarPU runtime system.
We describe a set of Fortran routines for generatig box-constrained nonlinear programming test problems. The technique, as described by Facchinei et al. (this issue), allows the user to control relevant properties of the generated problems
Domain decomposition ideas have long been an essential tool for the solution of PDEs on parallel computers. In recent years many research efforts have been focused on recursively employing domain decomposition methods to obtain multilevel preconditioners to be used with Krylov solvers. In this context, we developed MLD2P4 (MultiLevel Domain Decomposition Parallel Preconditioners Package based on PSBLAS), a package of parallel multilevel preconditioners that combines additive Schwarz domain decomposition methods with a smoothed aggregation technique to build a hierarchy of coarse-level corrections in an algebraic way. The design of MLD2P4 was guided by objectives such as extensibility, flexibility, performance, portability, and ease of use. They were achieved by following an object-based approach while using the Fortran 95 language, as well as by employing the PSBLAS library as a basic framework. In this article, we present MLD2P4 focusing on its design principles, software architecture, and use.
hpGEM, a novel framework for the implementation of discontinuous Galerkin finite element methods (FEMs), is described. We present data structures and methods that are common for many (discontinuous) FEMs and show how we have implemented the components as an object-oriented framework. This framework facilitates and accelerates the implementation of finite element programs, the assessment of algorithms, and their application to real-world problems. The article documents the status of the framework, exemplifies aspects of its philosophy and design, and demonstrates the feasibility of the approach with several application examples.
We explain why we feel that the comparison betwen Common Lisp and Fortran in a recent article by Fateman et al. in this journal is not entirely fair.
The software library hypre provides high-performance preconditioners and solvers for the solution of large, sparse linear systems on massively parallel computers as well as conceptual interfaces that allow users to access the library in the way they naturally think about their problems. These interfaces include a stencil-based structured interface (Struct); a semistructured interface (semiStruct), which is appropriate for applications that are mostly structured, for example, block structured grids, composite grids in structured adaptive mesh refinement applications, and overset grids; and a finite element interface (FEI) for unstructured problems, as well as a conventional linear-algebraic interface (IJ). It is extremely important to provide an efficient, scalable implementation of these interfaces in order to support the scalable solvers of the library, especially when using tens of thousands of processors. This article describes the data structures, parallel implementation, and resulting performance of the IJ, Struct and semiStruct interfaces. It investigates their scalability, presents successes as well as pitfalls of some of the approaches and suggests ways of dealing with them.
This article describes an ANSI Fortran 77 code, VLUGR3, autovectorizable on the Cray Y-MP, that is based on an adaptive-grid finite-difference method to solve time-dependent three-dimensional systems of partial differential equations.
Different automatic (also called universal or black-box) methods have been suggested to sample from univariate log-concave distributions. Our new automatic algorithm for bivariate log-concave distributions is based on the method of transformed density rejection. In order to construct a hat function for a rejection algorithm the bivariate density is transformed by the logarithm into a concave function. Then it is possible to construct a dominating function by taking the minimum of several tangent planes, which are by exponentiation transformed back into the original scale. The choice of the points of contact is automated using adaptive rejection sampling. This means that points that are rejected by the rejection algorithm can be used as additional points of contact. The article describes the details how this main idea can be used to construct Algorithm ALC2D that can generate random pairs from all bivariate log-concave distributions with known domain, computable density, and computable partial derivatives.
We describe Fortran subroutines for finding approximate solutions of the maximum planar subgraph problem (graph planarization) using a Greedy Randomized Adaptive Search Procedure (GRASP). The design and implementation of the code are described in detail. Computational results with the subroutines illustrate the quality of solutions found as a function of number of GRASP iterations.
SIPAMPL is an environment for coding semi-infinite programming (SIP) problems. This environment includes a database containing a set of SIP problems that have been collected from the literature and a set of routines. It allows users to code their own SIP problems in AMPL, to use any problem already in the database, and to develop and test any SIP solver. The SIPAMPL routines support the interface between a potential SIP solver and test problems coded in AMPL. SIPAMPL also provides a tool that allows the selection of problems from the database with specified characteristics. As a concept demonstration, we show how MATLAB can use SIPAMPL to solve the problems in the database. The Linux and Microsoft Windows versions together with the database of coded problems are freely available via the web.
With the advent of multicore processors, numerical and mathematical software relies on parallelism in order to benefit from hardware performance increases. We present the design and use of a Fortran 2003 wrapper for POSIX threads, called forthreads. Forthreads is complete in the sense that is provides native Fortran 2003 interfaces to all pthreads routines where possible. We demonstrate the use and efficiency of forthreads for SIMD parallelism and task parallelism. We present forthreads/MPI implementations that enable hybrid shared-/distributed-memory parallelism in Fortran 2003. Our benchmarks show that forthreads offers performance comparable to that of OpenMP, but better thread control and more freedom. We demonstrate the latter by presenting a multithreaded Fortran 2003 library for POSIX Internet sockets, enabling interactive numerical simulations with runtime control.
This article presents a portable C++ system for multiple precision calculations of special functions called e_float. It has an extendable architecture with a uniform C++ layer which can be used with any suitably prepared MP type. The system implements many high-precision special functions and extends some of these to very large parameter ranges. It supports calculations with 30 ? 300 decimal digits of precision. Interoperabilities with Microsoft�s� CLR, Python, and Mathematica� are supported. The e_float system and its usage are described in detail. Implementation notes, testing results, and performance measurements are provided.
A recent study by Akl indicates that Mifsud's algorithm, which involves unnecessary searching operations, is the fastest existing combination generator. A modified Page and Wilson's algorithm, which is essentially similar to Mifsud's algorithm, is presented. A theoretical analysis of the modified algorithm is also given.
Major breakthroughs in chip and software design have been observed for the last nine years. In October 2001, IBM released the world�s first multicore processor: POWER4. Six years later, in February 2007, NVIDIA made a public release of CUDA SDK, a set of development tools to write algorithms for execution on Graphic Processing Units (GPUs). Although software vendors have started working on parallelizing their products, the vast majority of existing code is still sequential and does not effectively utilize modern multicore CPUs and manycore GPUs. This article describes Parallel Colt, a multithreaded Java library for scientific computing and image processing. In addition to describing the design and functionality of Parallel Colt, a comparison to MATLAB is presented. Two ImageJ plugins for iterative image deblurring and motion correction of PET brain images are described as typical applications of this library. Performance comparisons with MATLAB, including GPU computations via AccelerEyes� Jacket toolbox are also given.
SRFPACK is a Fortran 77 software package that constructs a smooth interpolatory or approximating surface to data values associated with arbitrarily distributed points in the plane. It employs automatically selected tension factors to preserve shape properties of the data and to avoid overshoot and undershoot associated with steep gradients. The domain of the fitting function may be nonconvex or multiply connected, and the surface may be constrained to have discontinuous value or derivative across a user-specified curve representing, for example, a geological fault line. Although triangle based, the method provides a means of avoiding the inaccuracy associated with long thin triangles on the boundary of the convex hull of the data abscissae.
Pthreads is the library of POSIX standard functions for concurrent, multithreaded programming. The POSIX standard only defines an application programming interface (API) to the C programming language, not to Fortran. Many scientific and engineering applications are written in Fortran. Also, many of these applications exhibit functional, or task-level, concurrency. They would benefit from multithreading, especially on symmetric multiprocessors (SMP). We present here an interface to that part of the Pthreads library that is compatible with standard Fortran. The contribution consists of two primary source files: a Fortran module and a collection of C wrappers to Pthreads functions. The Fortran module defines the data structures, interface and initialization routines used to manage threads. The stability and portability of the Fortran API to Pthreads has been demonstrated using common mathematical computations on several SMP systems.
We present a stable and efficient Fortran implementation of polynomial interpolation at the Padua points on the square [???1,1]2. These points are unisolvent and their Lebesgue constant has minimal order of growth (log square of the degree). The algorithm is based on the representation of the Lagrange interpolation formula in a suitable orthogonal basis, and takes advantage of a new matrix formulation together with the machine-specific optimized BLAS subroutine for the matrix-matrix product. Extension to interpolation on rectangles, triangles and ellipses is also described.
The features of the new standard language Fortran 90 are introduced and discussed. In order to focus the discussion, the particular context is the conversiton of an existing published ACM Transactions on Mathematical Software algorithm from Fortran 77 to the new standard. Emphasis is on the new features of the language, including the array facilities, the use of modules, the applicability of user-defined (-derived) data types, the reduction in machine dependence of numeric codes, and the dynamic allocation of storage. The intent is that writers of software as well as those who use Fortran in scientific and engineering work will find this a helpful introduction to the new and powerful features of Fortran 90.
Several inprovements to algorithm 761 are presented. The problems corrected consist of (1) the computation of a determinant in subroutine SDLEQN may result in overflow, (2) subroutine SDTRCH may fail to correctly determine the set of boundary edges, (3) subroutine SDTRTT, which removes long thin triangles from the boundary in order to improve the accuracy of extrapolation, may remove too many triangles, and (4) the nodal derivative estimation procedure, SDPD3P, often fails to achieve cubic precision.
A new version of a Fortran multiprecision computation system, based on the Fortran 90 language, is described. With this new approach, a translator program is not required�translation of Fortran code for multiprecision is accomplished by merely utilizing advanced features of Fortran 90, such as derived data types and operator extensions. This approach results in more-reliable translation and permits programmers of multiprecision applications to utilize the full power of Fortran 90. Three multiprecision data types are supported in this system: multiprecision integer, real, and complex. All the usual Fortran conventions for mixed-mode operations are supported, and many of the Fortran intrinsics, such as SIN, EXP, and MOD, are supported with multiprecision arguments. An interesting application of this software, wherein new number-theoretic identities have been discovered by means of multiprecision computations, is included also.
List structures provide a general mechanism for representing easily changed structured data, but can introduce inefficiencies in the use of space when fields of uniform size are used to contain pointers to data and to link the structure. Empirically determined regularity can be exploited to provide more space-efficient encodings without losing the flexibility inherent in list structures. The basic scheme is to provide compact pointer fields big enough to accommodate most values that occur in them and to provide �escape� mechanisms for exceptional cases. Several examples of encoding designs are presented and evaluated, including two designs currently used in Lisp machines. Alternative escape mechanisms are described, and various questions of cost and implementation are discussed. In order to extrapolate our results to larger systems than those measured, we propose a model for the generation of list pointers and we test the model against data from two programs. We show that according to our model, list structures with compact cdr fields will, as address space grows, continue to be compacted well with a fixed-width small field. Our conclusion is that with a microcodable processor, about a factor of two gain in space efficiency for list structure can be had for little or no cost in processing time.
This paper defines a new variant of program slicing, called specialization slicing, and presents an algorithm for the specialization-slicing problem that creates an optimal output slice. An algorithm for specialization slicing is polyvariant: for a given procedure ?, the algorithm may create multiple specialized copies of ?. In creating specialized procedures, the algorithm must decide for which patterns of formal parameters a given procedure should be specialized and which program elements should be included in each specialized procedure. We formalize the specialization-slicing problem as a partitioning problem on the elements of the possibly infinite unrolled program. To manipulate possibly infinite sets of program elements, the algorithm makes use of automata-theoretic techniques originally developed in the model-checking community. The algorithm returns a finite answer that is optimal (with respect to a criterion defined in the article). In particular, (i) each element replicated by the specialization-slicing algorithm provides information about specialized patterns of program behavior that are intrinsic to the program, and (ii) the answer is of minimal size (i.e., among all possible answers with property (i), there is no smaller one). The specialization-slicing algorithm provides a new way to create executable slices. Moreover, by combining specialization slicing with forward slicing, we obtain a method for removing unwanted features from a program. While it was previously known how to solve the feature-removal problem for single-procedure programs, it was not known how to solve it for programs with procedure calls.
Many programming languages support either task parallelism, but few languages provide a uniform framework for writing applications that need both types of parallelism or data parallelism. We present a programming language and system that integrates task and data parallelism using shared objects. Shared objects may be stored on one processor or may be replicated. Objects may also be partitioned and distributed on several processors.Task parallelism is achieved by forking processes remotely and have them communicate and synchronize through objects. Data parallelism is achieved by executing operations on partitioned objects in parallel. Writing task-and data-parallel applications with shared objects has several advantages. Programmers use the objects as if they were stored in a memory common to all processors. On distributed-memory machines, if objects are remote, replicated, or partitioned, the system takes care of many low-level details such as data transfers and consistency semantics. In this article, we show how to write task-and data-parallel programs with our shared object model. We also desribe a portable implementation of the model. To assess the performance of the system, we wrote several applications that use task and data parallelism and excuted them on a collection of Pentium Pros connected by Myrinet. The performance of these applications is also discussed in this article.
Current parallelizing compilers can tackle applications exercising regular access patterns on arrays or affine indices, where data dependencies can be expressed in a linear form. Unfortunately, there are cases that independence between statements of code cannot be guaranteed and thus the compiler conservatively produces sequential code. Programs that involve extensive pointer use, irregular access patterns, and loops with unknown number of iterations are examples of such cases. This limits the extraction of parallelism in cases where dependencies are rarely or never triggered at runtime. Speculative parallelism refers to methods employed during program execution that aim to produce a valid parallel execution schedule for programs immune to static parallelization. The motivation for this article is to review recent developments in the area of compiler-driven software speculation for thread-level parallelism and how they came about. The article is divided into two parts. In the first part the fundamentals of speculative parallelization for thread-level parallelism are explained along with a design choice categorization for implementing such systems. Design choices include the ways speculative data is handled, how data dependence violations are detected and resolved, how the correct data are made visible to other threads, or how speculative threads are scheduled. The second part is structured around those design choices providing the advances and trends in the literature with reference to key developments in the area. Although the focus of the article is in software speculative parallelization, a section is dedicated for providing the interested reader with pointers and references for exploring similar topics such as hardware thread-level speculation, transactional memory, and automatic parallelization.
Constraint Logic Programming languages on Finite Domains, CLP(FD), provide a declarative framework for Artificial Intelligence problems. However, in many real life cases, domains are not known and must be acquired or computed. In systems that interact with the outer world, domain elements synthesize information on the environment, they are not all known at the beginning of the computation, and must be retrieved through an expensive acquisition process.In this article, we extend the CLP(FD) language by combining it with a new sort (called Incrementally specified Sets, I-Set). In the resulting language, CLP(FD + I-Set), FD variables can be defined on partially or fully unknown domains (I-Set). Domains can be linked each other through relations, and constraints can be imposed on them. We describe a propagation algorithm (called Known Arc Consistency (KAC)) based on known domain elements, and theoretically compare it with arc-consistency.The language can be implemented on top of different CLP systems, thus letting the user exploit different possible semantics for domains (e.g., lists, sets or streams). We state the specifications that the employed system should provide, and we show that two different CLP systems (Conjunto and {log}) can be effectively used.We provide motivating examples and describe promising applications.
Designing data types in isolation is fundamentally different from designing them for integration into communities of data types, especially when inheritance is a fundamental issue. Moreover, we can distinguish between the design of families�integrated types that are variations of each other�and more general communities where totally different but cohesive collections of types support specific applications (e.g., a compiler). We are concerned with the design of integrated families of data types as opposed to individual data types; that is, on the issues that arise when the focus is intermediate between the design of individual data types and more general communities of data types. We argue that design at this level is not adequately served by systems providing only class-based inheritance hierarchies and that systems which additionally provide a coupled subtype specification hierarchy are still not adequate. We propose a system that provides an unlimited number of uncoupled specification hi erarchies and illustrate it with three: a subtype hierarchy, a specialization/generalization hierarchy, and a like hierarchy. We also resurrect a relatively unknown Smalltalk design methodology that we call programming-by-exemplars and argue that it is an important addition to a designer's grab bag of techniques. The methodology is used to show that the subtype hierarchy must be decoupled from the inheritance hierarchy, something that other researchers have also suggested. However, we do so in the context of exemplar-based systems to additionally show that they can already support the extensions required without modification and that they lead to a better separation between users and implementers, since classes and exemplars can be related in more flexible ways. We also suggest that class-based systems need the notion of private types if they are to surmount their current limitations. Our points are made in the guise of designing a family of List data types. Among these is a new variety of lists that have never been previously published: prefix-sharing lists. We also argue that there is a need for familial classes to serve as an intermediary between users and the members of a family.
We consider a type algebra equipped with recursive, product, function, intersection, union, and complement types, together with type variables. We consider the subtyping relation defined by Castagna and Xu [2011] over such type expressions and show how this relation can be decided in EXPTIME, answering an open question. The novelty, originality and strength of our solution reside in introducing a logical modeling for the semantic subtyping framework. We model semantic subtyping in a tree logic and use a satisfiability-testing algorithm in order to decide subtyping. We report on practical experiments made with a full implementation of the system. This provides a powerful polymorphic type system aiming at maintaining full static type-safety of functional programs that manipulate trees, even with higher-order functions, which is particularly useful in the context of XML.
�Pure� SETL is a language of very high level allowing algorithms to be programmed rapidly and succintly. SETL's representation sublanguage adds a system of declarations which allow the user of the language to control the data structures that will be used to implement an algorithm which has already been written in pure SETL, so as to improve its efficiency. Ideally no rewriting of the algorithm should be necessary. The facilities provided by the representation sublanguage and the run-time data structures that it can generate are described; based on this a heuristic which uses some of the methods of global program analysis and which should be capable of selecting an acceptably efficient representation automatically is given.
SLG resolution uses tabling to evaluate nonfloundering normal logic pr ograms according to the well-founded semantics. The SLG-WAM, which forms the engine of the XSB system, can compute in-memory recursive queries an order of magnitute faster than current deductive databases. At the same time, the SLG-WAM tightly intergrates Prolog code with tabled SLG code, and executes Prolog code with minimal overhead compared to the WAM. As a result, the SLG-WAM brings to logic programming important termination and complexity properties of deductive databases. This article describes the architecture of the SLG-WAM for a powerful class of programs, the class of fixed-order dynamically stratified programs. We offer a detailed description of the algorithms, data structures, and instructions that the SLG-WAM adds to the WAM, and a performance analysis of engine overhead due to the extensions.
The functional programming style is increasingly popular in the research world, but functional languages still execute slowly relative to imperative languages. This is largely because the power and flexibility of functional languages restrict the amount of information readily available to the compiler, hindering its ability to generate good code. This article demonstrates that information about order of evaluation of expressions can be statically inferred for nonstrict functional programs and that optimizations based on this information can provide substantial speedups at runtime. We present an exact, nonstandard semantics called path semantics that models order of evaluation in a nonstrict, sequential functional language, and its computable abstraction, path analysis. We show how the information inferred by path analysis can be used to implement destructive aggregate updating, in which updates on functional aggregates that are provably not live are done destructively. We also demonstrate a new approach to strictness analysis and show that strictness analysis is subsumed by path analysis. Benchmarks are presented.
A fast algorithm for finding dominators in a flowgraph is presented. The algorithm uses depth-first search and an efficient method of computing functions defined on paths in trees. A simple implementation of the algorithm runs in O(m log n) time, where m is the number of edges and n is the number of vertices in the problem graph. A more sophisticated implementation runs in O(m&agr;(m, n)) time, where &agr;(m, n) is a functional inverse of Ackermann's function. Both versions of the algorithm were implemented in Algol W, a Stanford University version of Algol, and tested on an IBM 370/168. The programs were compared with an implementation by Purdom and Moore of a straightforward O(mn)-time algorithm, and with a bit vector algorithm described by Aho and Ullman. The fast algorithm beat the straightforward algorithm and the bit vector algorithm on all but the smallest graphs tested.
Static program analysis is concerned with the computation of approximations of the runtime behavior of programs. Precise information about a program's runtime behavior is, in general, uncomputable for various different reasons, and each reason may necessitate making certain approximations in the information computed. This article illustrates one source of difficulty in static analysis of concurrent programs. Specifically, the article shows that an analysis that is simultaneously both context-sensitive and synchronization-sensitive (that is, a context-sensitive analysis that precisely takes into account the constraints on execution order imposed by the synchronization statements in the program) is impossible even for the simplest of analysis problems.
Some of the most difficult questions to answer when designing a distributed application are related to mobility: what information to transfer between sites and when and how to transfer it. Network-transparent distribution, the property that a program's behavior is independent of how it is partitioned among sites, does not directly address these questions. Therefore we propose to extend all language entities with a network behavior that enables efficient distributed programming by giving the programmer a simple and predictable control over network communication patterns. In particular, we show how to give objects an arbitrary mobility behavior that is independent of the objects definition. In this way, the syntax and semantics of objects are the same regardless of whether they are used as stationary servers, mobile agents, or simply as caches. These ideas have been implemented in Distributed Oz, a concurrent object-oriented language that is state aware and has dataflow synchronization. We prove that the implementation of objects in Distributed Oz is network transparent. To satisfy the predictability condition, the implementation avoids forwarding chains through intermediate sites. The implementation is an extension to the publicly available DFKI Oz 2.0 system.
Optimizing exception handling is critical for programs that frequently throw exceptions. We observed that there are many such exception-intensive programs written in Java. There are two commonly used exception handling techniques, stack unwinding and stack cutting. Stack unwinding optimizes the normal path by leaving the exception handling path unoptimized, while stack cutting optimizes the exception handling path by adding extra work to the normal path. However, there has been no single exception handling technique to optimize the exception handling path without incurring any overhead to the normal path.We propose a new technique called Exception-Directed Optimization (EDO) that optimizes exception-intensive programs without slowing down exception-minimal programs. It is a feedback-directed dynamic optimization consisting of three steps: exception path profiling, exception path inlining, and throw elimination. Exception path profiling attempts to detect hot exception paths. Exception path inlining embeds every hot exception path into the corresponding catching method. Throw elimination replaces a throw with a branch to the corresponding handler. We implemented EDO in IBM's production Just-in-Time compiler and made several experiments. In summary, it improved the performance of exception-intensive programs by up to 18.3% without decreasing the performance of exception-minimal programs for SPECjvm98. We also found an opportunity for performance improvement using EDO in the startup of a Java application server.
One way to model a sound and complete translation from a source calculus into a target calculus is with an adjoint or a Galois connection. In the special case of a reflection, one also has that the target calculus is isomorphic to a subset of the source. We show that three widely studied translations form reflections. We use as our source language Moggi's computational lambda calculus, which is an extension of Plotkin's call-by-value calculus. We show that Plotkin's CPS translation, Moggi's monad translation, and Girard's translation to linear logic can all be regarded as reflections form this source language, and we put forward the computational lambda calculus as a model of call-by-value computation that improves on the traditional call-by-value calculus. Our work strengthens Plotkin's and Moggi's original results and improves on recent work based on equational correspondence, which uses equations rather than reductions.
The language JavaGI extends Java 1.5 conservatively by a generalized interface mechanism. The generalization subsumes retroactive and type-conditional interface implementations, binary methods, symmetric multiple dispatch, interfaces over families of types, and static interface methods. These features make certain coding patterns redundant, increase the expressiveness of the type system, and permit solutions to extension and integration problems with components in binary form, for which previously several unrelated extensions had been suggested. This article explains JavaGI and motivates its design. Moreover, it formalizes a core calculus for JavaGI and proves type soundness, decidability of typechecking, and determinacy of evaluation. The article also presents the implementation of a JavaGI compiler and an accompanying run-time system. The compiler, based on the Eclipse Compiler for Java, offers mostly modular static typechecking and fully modular code generation. It defers certain well-formedness checks until load time to increase flexibility and to enable full support for dynamic loading. Benchmarks show that the code generated by the compiler offers good performance. Several case studies demonstrate the practical utility of the language and its implementation.
Software systems represent a hierarchy of modules. Client modules contain sets of procedures that extend the capabilities of imported modules. This concept of extension is here applied to data types. Extended types are related to their ancestor in terms of a hierarchy. Variables of an extended type are compatible with variables of the ancestor type. This scheme is expressed by three language constructs only: the declaration of extended record types, the type test, and the type guard. The facility of extended types, which closely resembles the class concept, is defined in rigorous and concise terms, and an efficient implementation is presented.
Compositional theories are crucial when designing large and complex systems from smaller components. In this work we propose such a theory for synchronous concurrent systems. Our approach follows so-called interface theories, which use game-theoretic interpretations of composition and refinement. These are appropriate for systems with distinct inputs and outputs, and explicit conditions on inputs that must be enforced during composition. Our interfaces model systems that execute in an infinite sequence of synchronous rounds. At each round, a contract must be satisfied. The contract is simply a relation specifying the set of valid input/output pairs. Interfaces can be composed by parallel, serial or feedback composition. A refinement relation between interfaces is defined, and shown to have two main properties: (1) it is preserved by composition, and (2) it is equivalent to substitutability, namely, the ability to replace an interface by another one in any context. Shared refinement and abstraction operators, corresponding to greatest lower and least upper bounds with respect to refinement, are also defined. Input-complete interfaces, that impose no restrictions on inputs, and deterministic interfaces, that produce a unique output for any legal input, are discussed as special cases, and an interesting duality between the two classes is exposed. A number of illustrative examples are provided, as well as algorithms to compute compositions, check refinement, and so on, for finite-state interfaces.
Recent work on embedding object languages into Haskell use "phantom types" (i.e., parameterized types whose parameter does not occur on the right-hand side of the type definition) to ensure that the embedded object-language terms are simply typed. But is it a safe assumption that only simply-typed terms can be represented in Haskell using phantom types? And conversely, can all simply-typed terms be represented in Haskell under the restrictions imposed by phantom types? In this article we investigate the conditions under which these assumptions are true: We show that these questions can be answered affirmatively for an idealized Haskell-like language and discuss to which extent Haskell can be used as a meta-language.
The most intuitive memory model for shared-memory multi-threaded programming is sequential consistency (SC), but it disallows the use of many compiler and hardware optimizations and thus affects performance. Data-race-free (DRF) models, such as the C++11 memory model, guarantee SC execution for data-race-free programs. But these models provide no guarantee at all for racy programs, compromising the safety and debuggability of such programs. To address the safety issue, the Java memory model, which is also based on the DRF model, provides a weak semantics for racy executions. However, this semantics is subtle and complex, making it difficult for programmers to reason about their programs and for compiler writers to ensure the correctness of compiler optimizations. We present the drfx memory model, which is simple for programmers to understand and use while still supporting many common optimizations. We introduce a memory model (MM) exception that can be signaled to halt execution. If a program executes without throwing this exception, then drfx guarantees that the execution is SC. If a program throws an MM exception during an execution, then drfx guarantees that the program has a data race. We observe that SC violations can be detected in hardware through a lightweight form of conflict detection. Furthermore, our model safely allows aggressive compiler and hardware optimizations within compiler-designated program regions. We formalize our memory model, prove several properties of this model, describe a compiler and hardware design suitable for drfx, and evaluate the performance overhead due to our compiler and hardware requirements.
Through the use of conditional compilation and related tools, many software projects can be used to generate a huge number of related programs. The problem of typing such variational software is difficult. The brute-force strategy of generating all variants and typing each one individually is: (1) usually infeasible for efficiency reasons and (2) produces results that do not map well to the underlying variational program. Recent research has focused mainly on efficiency and addressed only the problem of type checking. In this work we tackle the more general problem of variational type inference and introduce variational types to represent the result of typing a variational program. We introduce the variational lambda calculus (VLC) as a formal foundation for research on typing variational programs. We define a type system for VLC in which VLC expressions are mapped to correspondingly variational types. We show that the type system is correct by proving that the typing of expressions is preserved over the process of variation elimination, which eventually results in a plain lambda calculus expression and its corresponding type. We identify a set of equivalence rules for variational types and prove that the type unification problem modulo these equivalence rules is unitary and decidable; we also present a sound and complete unification algorithm. Based on the unification algorithm, the variational type inference algorithm is an extension of algorithm W. We show that it is sound and complete and computes principal types. We also consider the extension of VLC with sum types, a necessary feature for supporting variational data types, and demonstrate that the previous theoretical results also hold under this extension. Finally, we characterize the complexity of variational type inference and demonstrate the efficiency gains over the brute-force strategy.
Although the use of abstract types has been widely advocated as a specification and implementation technique, their use has often been associated with programming languages that are not widely available, and examples published to date are rarely taken from actual applications. SIMULA is a widely available language that supports the use of abstract types. The purposes of this paper are (1) to demonstrate the application of the concepts of data abstraction to a common problem; (2) to demonstrate the use of data abstraction in a widely available language; and (3) to provide a portable facility for statistics collection that may make the use of SIMULA more attractive. A discussion of the background of and requirements for an abstract type for statistics collection is presented, followed by a specification for the type using traces. A SIMULA implementation, with examples of its use, is given. Finally, implementation of the abstract type in other languages is discussed.
We propose a rank 2 intersection type system with new typing rules for local definitions (let-expressions and letrec-expressions) and conditional expressions (if-expressions and match-expressions). This is a further step towards the use of intersection types in "real" programming languages.The technique for typing local definitions relies entirely on the principal typing property (i.e. it does not depend on particulars of rank 2 intersection), so it can be applied to any system with principal typings. The technique for typing conditional expressions, which is based on the idea of introducing metrics on types to "limit the use" of the intersection type constructor in the types assigned to the branches of the conditionals, is instead tailored to rank 2 intersection. However, the underlying idea might also be useful for other type systems.
The SSAPRE algorithm for performing partial redundancy elimination based entirely on SSA form is presented. The algorithm is formulated based on a new conceptual framework, the factored redundancy graph, for analyzing redundancy, and representes the first sparse approach to the classical problem and on methods for its solution. With the algorithm description, theorems and their proofs are given showing that the algorithm produces the best possible code by the criteria of computational optimality and lifetime optimality of the introduced temporaries. In addition to the base algorithm, a practical implementation of SSAPRE that exhibits additional compile-time efficiencies is described. In closing, measurement statistics are provided that characterize the instances of the partial redundancy problem from a set of benchmark programs and compare optimization time spent by an implementation of SSAPRE aganist a classical partial redundancy elimination implementation. The data lend insight into the nature of partial redundancy elimination and demonstrate the expediency of this new approach.
Big data is revolutionizing how all sectors of our economy do business, including telecommunication, transportation, medical, and finance. Big data comes in two flavors: data at rest and data in motion. Processing data in motion is stream processing. Stream processing for big data analytics often requires scale that can only be delivered by a distributed system, exploiting parallelism on many hosts and many cores. One such distributed stream processing system is IBM Streams. Early customer experience with IBM Streams uncovered that another core requirement is extensibility, since customers want to build high-performance domain-specific operators for use in their streaming applications. Based on these two core requirements of distribution and extensibility, we designed and implemented the Streams Processing Language (SPL). This article describes SPL with an emphasis on the language design, distributed runtime, and extensibility mechanism. SPL is now the gateway for the IBM Streams platform, used by our customers for stream processing in a broad range of application domains.
Dynamically dispatched calls often limit the performance of object-oriented programs, since opject-oriented programming encourages factoring code into small, reusable units, thereby increasing the frequency of these expensive operations. Frequent calls not only slow down execution with the dispatch overhead per se, but more importantly they hinder optimization by limiting the range and effectiveness of standard global optimizations. In particular, dynamically dispatched calles prevent standard interprocedual optimizations that depend on the availability of a static call graph. The SELF implementation described here offers tow novel approaches to optimization. Type feedback speculatively inlines dynamically dispatched calls based on profile information that predicts likely receiver classes. Adaptive optimization reconciles optimizing compilation with interactive performance by incrementally optimizing only the frequently executed parts of a program. When combined, these two techniques result in a system that can execute programs significantly faster than previous systems while retaining much of the interactiveness of an interpreted system.
Program transformations are proposed as a means of providing fair parallelism semantics for parallel programs with shared variables. The transformations are developed in two steps. First, abstract schedulers that implement the various fairness policies are introduced. These schedulers use random assignments z := ? to represent the unbounded nondeterminism induced by fairness. Concrete schedulers are derived by suitably refining the ?. The transformations are then obtained by embedding the abstract schedulers into the parallel programs. This embedding is proved correct on the basis of a simple transition semantics. Since the parallel structure of the original program is preserved, the transformations also provide a basis for syntax-directed proofs of total correctness under the fairness assumption. These proofs make use of infinite ordinals.
This article presents Forma, a practical, safe, and automatic data reshaping framework that reorganizes arrays to improve data locality. Forma splits large aggregated data-types into smaller ones to improve data locality. Arrays of these large data types are then replaced by multiple arrays of the smaller types. These new arrays form natural data streams that have smaller memory footprints, better locality, and are more suitable for hardware stream prefetching. Forma consists of a field-sensitive alias analyzer, a data type checker, a portable structure reshaping planner, and an array reshaper. An extensive experimental study compares different data reshaping strategies in two dimensions: (1) how the data structure is split into smaller ones (maximal partition � frequency-based partition � affinity-based partition); and (2) how partitioned arrays are linked to preserve program semantics (address arithmetic-based reshaping � pointer-based reshaping). This study exposes important characteristics of array reshaping. First, a practical data reshaper needs not only an inter-procedural analysis but also a data-type checker to make sure that array reshaping is safe. Second, the performance improvement due to array reshaping can be dramatic: standard benchmarks can run up to 2.1 times faster after array reshaping. Array reshaping may also result in some performance degradation for certain benchmarks. An extensive micro-architecture-level performance study identifies the causes for this degradation. Third, the seemingly naive maximal partition achieves best or close-to-best performance in the benchmarks studied. This article presents an analysis that explains this surprising result. Finally, address-arithmetic-based reshaping always performs better than its pointer-based counterpart.
The multiple assignment statement is defined in full generality�including assignment to subscripted variables and record fields�using the �axiomatic� approach of Hoare. Proof rules are developed for calls of procedures using global variables, var parameters, result parameters, and value parameters, using the idea of multiple assignment to provide understanding. An attempt is made to clarify some issues that have arisen concerning the use of rules of inference to aid in generating �verification conditions� in mechanical verifiers and the use of logical variables to denote initial values of program variables.
The problem of inferring array shapes ahead of time in languages that exhibit both implicit and dynamic typing is a critical one because the ramifications of its solution are the better organization of array storage through compaction and reuse, and the generation of high-performance code through specialization by shape. This article addresses the problem in a prototypical implicitly and dynamically typed array language called MATLAB. The approach involves modeling the language's shape semantics using an algebraic system, and applying term rewriting techniques to evaluate expressions under this algebra. Unlike prior efforts at array shape determination, this enables the deduction of valuable shape information even when array extents are compile-time unknowns. Furthermore, unlike some previous methods, our approach doesn't impose monotonicity requirements on an operator's shape semantics. The work also describes an inference methodology and reports measurements from a type inference engine called MAGICA. In a benchmark suite of 17 programs, the shape inference subsystem in MAGICA detected the equivalence of over 61% of the symbolic shapes in six programs, and over 57% and 37% of the symbolic shapes in two others. In the remaining nine programs, all array shapes were inferred to be compile-time constants.
A concurrent object is a data structure shared by concurrent processes. Conventional techniques for implementing concurrent objects typically rely on critical sections; ensuring that only one process at a time can operate on the object. Nevertheless, critical sections are poorly suited for asynchronous systems: if one process is halted or delayed in a critical section, other, nonfaulty processes will be unable to progress. By contrast, a concurrent object implementation is lock free if it always guarantees that some process will complete an operation in a finite number of steps, and it is wait free if it guarantees that each process will complete an operation in a finite number of steps. This paper proposes a new methodology for constructing lock-free and wait-free implementations of concurrent objects. The object's representation and operations are written as stylized sequential programs, with no explicit synchronization. Each sequential operation is atutomatically transformed into a lock-free or wait-free operation using novel synchronization and memory management algorithms. These algorithms are presented for a multiple instruction/multiple data (MIMD) architecture in which n processes communicate by applying atomic read, write, load_linked, and store_conditional operations to a shared memory.
Constraing propagation algorithms form an important part of most of the constraint programming systems. We provide here a simple, yet very general framework that allows us to explain several constraint propagation algorithms in a systematic way. In this framework we proceed in two steps. First, we introduce a generic iteration algorithm on partial orderings and prove its correctness in an abstract setting. Then we instantiate this algorithm with specific partial orderings and functions to obtain specific constraint propagation algorithms. In particular, using the notions commutativity and semi-commutativity, we show that the AC-3, PC-2, DAC, and DPC algorithms for achieving (directional) arc consistency and (directional) path consistency are instances of a single generic algorithm. The work reported here extends and simplifies that of Apt [1999a].
The assembled length of a span-dependent jump instruction depends on the distance between the instruction and its target. Such instructions are found on many computers and typically have two forms, long and short. We consider the problem of minimizing object program length for such machines by chaining together jumps with the same target. Although the problem is NP-complete in its most general form, several mildly restricted forms of the problem exist that are of practical importance and have efficient solutions.
Parallel functional languages often use meta-linguistic annotations to provide control over parallel evaluation. In this paper we explore a flexible mechanism to control when an expression is evaluated: first-class monadic schedules. We discuss the advantages of using such first-class values over traditional annotation-based systems. In particular, it is often desirable to make decisions about the operational behavior of parallel programs depending on the dynamic state of the system. For example, we may want to measure the system load before deciding to evaluate expressions in parallel. For this purpose, we show how monads can be used to access dynamic system parameters in a referentially transparent manner (up to termination).As a mechanism to reason about schedules, we present a set of algebraic properties that any implementation of schedules must satisfy. We also describe an implementation that translates schedules into a dialect of Scheme extended with futures. We prove that this implementation satisfies the given set of algebraic properties, and give performance results for a parallel solution to the n-body problem using the Barnes--Hut method.Although our ideas were developed specifically for nonstrict functional languages such as Haskell, we briefly discuss how they can be used with strict functional languages and imperative languages as well.
The �intermittent assertion� method for proving programs correct is explained and compared with the conventional method. Simple conventional proofs of iterative algorithms that compute recursively defined functions, including Ackermann's function, are given.
Action systems provide a method to program distributed systems that emphasizes the overall behavior of the system. System behavior is described in terms of the possible interactions (actions) that the processes can engage in, rather than in terms of the sequential code that the processes execute. The actions provide a symmetric communication mechanism that permits an arbitrary number of processes to be synchronized by a common handshake. This is a generalization of the usual approach, employed in languages like CSP and Ada, in which communication is asymmetric and restricted to involve only two processes. Two different execution models are given for action systems: a sequential one and a concurrent one. The sequential model is easier to use for reasoning, and is essentially equivalent to the guarded iteration statement by Dijkstra. It is well suited for reasoning about system properties in temporal logic, but requires a stronger fairness notion than it is reasonable to assume a distributed implementation will support. The concurrent execution model reflects the true concurrency that is present in a distributed execution, and corresponds to the way in which the system is actually implemented. An efficient distributed implementation of action systems on a local area network is described. The fairness assumptions of the concurrent model can be guaranteed in this implementation. The relationship between the two execution models is studied in detail in the paper. For systems that will be called fairly serializable, the two models are shown to be equivalent. Proof methods are given for verifying this property of action systems. It is shown that for fairly serializable systems, properties that hold for any concurrent execution of the system can be established by temporal proofs that are conducted entirely within the simpler sequential execution model.
Component-based programming is an increasingly prevalent theme in software development, motivating the need for expressive and safe module interconnection languages. Dynamic linking is an important requirement for module interconnection languages, as exemplified by dynamic link libraries (DLLs) and class loaders in operating systems and Java, respectively. A semantics is given for a type-safe module interconnection language that supports shared libraries and dynamic linking, as well as circular import dependencies (recursive modules). The core language requirements of the module interconnection language are compatible with programming languages such as Java and C#.
Software Transactional Memory (STM) is an attractive basis for the development of language features for concurrent programming. However, the semantics of these features can be delicate and problematic. In this article we explore the trade-offs semantic simplicity, the viability of efficient implementation strategies, and the flexibility of language constructs. Specifically, we develop semantics and type systems for the constructs of the Automatic Mutual Exclusion (AME) programming model; our results apply also to other constructs, such as atomic blocks. With this semantics as a point of reference, we study several implementation strategies. We model STM systems that use in-place update, optimistic concurrency, lazy conflict detection, and rollback. These strategies are correct only under nontrivial assumptions that we identify and analyze. One important source of errors is that some efficient implementations create dangerous �zombie� computations where a transaction keeps running after experiencing a conflict; the assumptions confine the effects of these computations.
Since its introduction by Joseph A. Fisher in 1979, trace scheduling has influenced much of the work on compile-time ILP (Instruction Level Parallelism) transformations. Initially developed for use in microcode compaction, it quickly became the main technique for machine-level compile-time parallelism exploitation. Although it has been used since the 1980s in many state-of-the-art compilers (e.g., Intel, Fujitsu, HP), a rigorous theory of trace scheduling is still lacking in the existing literature. This is reflected in the ad hoc way compensation code is inserted after a trace compaction, in the total absence of any attempts to measure the size of that compensation code, and so on. The aim of this article is to create a mathematical theory of the foundation of trace scheduling. We give a clear algorithm showing how to insert compensation code after a trace is replaced with its schedule, and then prove that the resulting program is indeed equivalent to the original program. We derive an upper bound on the size of that compensation code, and show that this bound can be actually attained. We also give a very simple proof that the trace scheduling algorithm always terminates.
Dataflow languages provide natural support for specifying constraints between objects in dynamic applications, where programs need to react efficiently to changes in their environment. In this article, we show that one-way dataflow constraints, largely explored in the context of interactive applications, can be seamlessly integrated in any imperative language and can be used as a general paradigm for writing performance-critical reactive applications that require efficient incremental computations. In our framework, programmers can define ordinary statements of the imperative host language that enforce constraints between objects stored in special memory locations designated as �reactive.� Reactive objects can be of any legal type in the host language, including primitive data types, pointers, arrays, and structures. Statements defining constraints are automatically re-executed every time their input memory locations change, letting a program behave like a spreadsheet where the values of some variables depend on the values of other variables. The constraint-solving mechanism is handled transparently by altering the semantics of elementary operations of the host language for reading and modifying objects. We provide a formal semantics and describe a concrete embodiment of our technique into C/C++, showing how to implement it efficiently in conventional platforms using off-the-shelf compilers. We discuss common coding idioms and relevant applications to reactive scenarios, including incremental computation, observer design pattern, data structure repair, and software visualization. The performance of our implementation is compared to problem-specific change propagation algorithms, as well as to language-centric approaches such as self-adjusting computation and subject/observer communication mechanisms, showing that the proposed approach is efficient in practice.
This work considers type systems that are defined by type-graphs (tgraphs), which are rooted directed graphs with order among the edges leaving each node. Tgraphs are uniquely mapped into polynomials which, in turn, are each evaluated at a special point to yield an irrational number named the tgraph's magic number. This special point is chosen using the Schanuel conjecture. It is shown that each tgraph can be uniquely represented by this magic number; namely, types are equal if and only if the corresponding magic numbers are equal. Since irrational numbers require infinite precision, the algorithm for generating magic numbers is carried out using a double-precision floating-point approximation. This approximation is viewed as a hashing scheme, mapping the infinite domain of the irrational numbers into finite computer words. The proposed hashing scheme was investigated experimentally, with the conclusion that it is a good and practical hashing method. In tests involving over a million randomly chosen tgraphs, we have not encountered a single collision. We conclude that this method for representation and management of types is practical, and offers novel possibilities for enforcing strict type matching at link time among separately compiled modules.
The programming language Mezzo is equipped with a rich type system that controls aliasing and access to mutable memory. We give a comprehensive tutorial overview of the language. Then we present a modular formalization of Mezzo�s core type system, in the form of a concurrent ?-calculus, which we successively extend with references, locks, and adoption and abandon, a novel mechanism that marries Mezzo�s static ownership discipline with dynamic ownership tests. We prove that well-typed programs do not go wrong and are data-race free. Our definitions and proofs are machine checked.
Java offers interesting opportunities for parallel computing. In particular, Java Remote Method Invocation (RMI) provides a flexible kind of remote procedure call (RPC) that supports polymorphism. Sun's RMI implementation achieves this kind of flexibility at the cost of a major runtime overhead. The goal of this article is to show that RMI can be implemented efficiently, while still supporting polymorphism and allowing interoperability with Java Virtual Machines (JVMs). We study a new approach for implementing RMI, using a compiler-based Java system called Manta. Manta uses a native (static) compiler instead of a just-in-time compiler. To implement RMI efficiently, Manta exploits compile-time type information for generating specialized serializers. Also, it uses an efficient RMI protocol and fast low-level communication protocols.A difficult problem with this approach is how to support polymorphism and interoperability. One of the consequences of polymorphism is that an RMI implementation must be able to download remote classes into an application during runtime. Manta solves this problem by using a dynamic bytecode compiler, which is capable of compiling and linking bytecode into a running application. To allow interoperability with JVMs, Manta also implements the Sun RMI protocol (i.e., the standard RMI protocol), in addition to its own protocol.We evaluate the performance of Manta using benchmarks and applications that run on a 32-node Myrinet cluster. The time for a null-RMI (without parameters or a return value) of Manta is 35 times lower than for the Sun JDK 1.2, and only slightly higher than for a C-based RPC protocol. This high performance is accomplished by pushing almost all of the runtime overhead of RMI to compile time. We study the performance differences between the Manta and the Sun RMI protocols in detail. The poor performance of the Sun RMI protocol is in part due to an inefficient implementation of the protocol. To allow a fair comparison, we compiled the applications and the Sun RMI protocol with the native Manta compiler. The results show that Manta's null-RMI latency is still eight times lower than for the compiled Sun RMI protocol and that Manta's efficient RMI protocol results in 1.8 to 3.4 times higher speedups for four out of six applications.
The formal definition of any namespace device found in a programming language can be given in terms of transformations on a semantic environment. It is worthwhile, therefore, to consider the implications of incorporating environments as bona fide data objects in a programming system. In this article, we propose a treatment of environments and the mechanism by which they are reified and manipulated, that addresses these concerns. The language described below (Rascal) permits environments to be reified into data structures, and data structures to be reflected into environments, but gives users great flexibility to constrain the extent and scope of these processes. We argue that the techniques and operators developed define a cohesive basis for building large-scale modular systems using reflective programming techniques.
Reasoning about multithreaded object-oriented programs is difficult, due to the nonlocal nature of object aliasing and data races. We propose a programming regime (or programming model) that rules out data races, and enables local reasoning in the presence of object aliasing and concurrency. Our programming model builds on the multithreading and synchronization primitives as they are present in current mainstream programming languages. Java or C# programs developed according to our model can be annotated by means of stylized comments to make the use of the model explicit. We show that such annotated programs can be formally verified to comply with the programming model. If the annotated program verifies, the underlying Java or C# program is guaranteed to be free from data races, and it is sound to reason locally about program behavior. Verification is modular: a program is valid if all methods are valid, and validity of a method does not depend on program elements that are not visible to the method. We have implemented a verifier for programs developed according to our model in a custom build of the Spec# programming system, and we have validated our approach on a case study.
A new programming language construct, called DOupon, subsumes Dijkstra's selective (IF) and iterative (DO) constructs. DOupon has a predicate transformer approximately equivalent in complexity to that for DO. In addition, it simplifies a wide variety of algorithms, in form as well as in discovery and proof. Several theorems are demonstrated that are useful for correctness proofs and for optimization and that are not applicable to DO or IF. The general usefulness of DOupon derives from a separation of the concerns of invariance, through iteration, from those of termination.
Dynamic memory allocation is ubiquitous in today's runtime environments. Allocation and deallocation of objects during program execution may cause fragmentation and foil the program's ability to allocate objects. Robson [1971] has shown that a worst-case scenario can create a space overhead within a factor of log n of the space that is actually required by the program, where n is the size of the largest possible object. Compaction can eliminate fragmentation, but is too costly to be run frequently. Many runtime systems employ partial compaction, in which only a small fraction of the allocated objects are moved. Partial compaction reduces some of the existing fragmentation at an acceptable cost. In this article we study the effectiveness of partial compaction and provide the first rigorous lower and upper bounds on its effectiveness in reducing fragmentation at a low cost.
The process models of Ada and occam are formally based on the CSP process algebra. However, for fine-tuning real-time performance, they include �prioritized� constructs that have no counterparts in CSP. These constructs therefore lack any formal definition, a situation that leaves room for misunderstandings. We extend CSP with a formal definition of the notion of priority. The definition is then used to assess the transputer implementation of priority in occam and the definition of priority in Ada.
Arrays of characters are a basic data type in many programming languages, but strings and substrings are seldom accorded first-class status as parameters and return values. Such status would enable a routine that calls a search function to readily access context on both sides of a return value. To enfranchise substrings, this paper describes a new data type for substrings as a special case of one for general subsequences. The key idea is that values are not sequences or references to positions in sequences, but rather references to subsequences. Primitive operations on the data type are constants, concatenation, and four new functions�base, start, next, and extent�which map subsequence references to subsequence references. This paper informally presents the data type, demonstrates its convenience for defining search functions, and shows how it can be concisely implemented. Examples are given in Ness, a language incorporating the new data type, which is implemented as part of the Andrew User Interface System.
SNOBOL4 is best known for its string processing facilities, which are based on patterns as data objects. Despite the demonstrated success of patterns, there are many shortcomings associated with their use. The concept of patterns in SNOBOL4 is examined and problem areas are discussed. An alternative method for high-level string processing is described. This method, implemented in the programming language Icon, employs generators, which are capable of producing alternative values. Generators, coupled with a goal-driven method of expression evaluation, provide the string processing facilities of SNOBOL4 without the disadvantages associated with patterns. Comparisons between SNOBOL4 and Icon are included and the broader implications of the new approach are discussed.
Jade is a portable, implicitly parallel language designed for exploiting task-level concurrency.Jade programmers start with a program written in a standard serial, imperative language, then use Jade constructs to declare how parts of the program access data. The Jade implementation uses this data access information to automatically extract the concurrency and map the application onto the machine at hand. The resulting parallel execution preserves the semantics of the original serial program. We have implemented Jade as an extension to C, and Jade implementations exist for s hared-memory multiprocessors, homogeneous message-passing machines, and heterogeneous networks of workstations. In this atricle we discuss the design goals and decisions that determined the final form of Jade and present an overview of the Jade implementation. We also present our experience using Jade to implement several complete scientific and engineering applications. We use this experience to evaluate how the different Jade language features were used in practice and how well Jade as a whole supports the process of developing parallel applications. We find that the basic idea of preserving the serial semantics simplifies the program development process, and that the concept of using data access specifications to guide the parallelization offers significant advantages over more traditional control-based approaches. We also find that the Jade data model can interact poorly with concurrency patterns that write disjoint pieces of a single aggregate data structure, although this problem arises in only one of the applications.
Owicki and Gries have developed a proof system for conditional critical regions. In their system, logically related variables accessed by more than one process are grouped together as resources, and processes are allowed access to a resource only in a critical region for that resource. Proofs of synchronization properties are constructed by devising predicates called resource invariants which describe relationships among the variables of a resource when no process is in a critical region for the resource. In constructing proofs using the system of Owicki and Gries, the programmer is required to supply the resource invariants. Methods are developed in this paper for automatically synthesizing resource invariants. Specifically, the resource invariants of a concurrent program are characterized as least fixpoints of a functional which can be obtained from the text of the program. By the use of this fixpoint characterization and a widening operator based on convex closure, good approximations may be obtained for the resource invariants of many concurrent programs.
Fairness is a mathematical abstraction: in a multiprogramming environment, fairness abstracts the details of admissible (�fair�) schedulers; in a distributed environment, fairness abstracts the relative speeds of processors. We argue that the standard definition of fairness often is unnecessarily weak and can be replaced by the stronger, yet still abstract, notion of finitary fairness. While standard weak fairness requires that no enabled transition is postponed forever, finitary weak fairness requires that for every computation of a system there is an unknown bound k such that no enabled transition is postponed more than k consecutive times. In general, the finitary restriction fin(F) of any given fairness requirement Fis the union of all &ohgr;-regular safety properties contained in F. The adequacy of the proposed abstraction is shown in two ways. Suppose we prove a program property under the assumption of finitary fairness. In a multiprogramming environment, the program then satisfies the property for all fair finite-state schedulers. In a distributed environment, the program then satisfies the property for all choices of lower and upper bounds on the speeds (or timings) of processors. The benefits of finitary fairness are twofold. First, the proof rules for verifying liveness properties of concurrent programs are simplified: well-founded induction over the natural numbers is adequate to prove termination under finitary fairness. Second, the fundamental problem of consensus in a faulty asynchronous distributed environment can be solved assuming finitary fairness.
Reclassification changes the class membership of an object at run-time while retaining its identity. We suggest language features for object reclassification, which extend an imperative, typed, class-based, object-oriented language.We present our proposal through the language Fickle??. The imperative features, combined with the requirement for a static and safe type system, provided the main challenges. We develop a type and effect system for Fickle?? and prove its soundness with respect to the operational semantics. In particular, even though objects may be reclassified across classes with different members, there will never be an attempt to access nonexisting members.
First-class classes enable programmers to abstract over patterns in the class hierarchy and to experiment with new forms of object-oriented programming such as mixins and traits. This increase in expressive power calls for tools to control the complexity of the software architecture. A contract system is one possible tool that has seen much use in object-oriented programming languages, but existing contract systems cannot cope with first-class classes. On the one hand, the typical contract language deals only with plain values such as numbers, while classes are higher-order values. On the other hand, contract specifications are usually contained within class definitions, while classes as values call for a separate contract language. This article presents the design and implementation of a contract system for first-class classes as well as a two-pronged evaluation. The first one states and proves a �blame correctness� theorem for a model of our language. The theorem shows that when the contract system assigns blame to a component for a contract violation, the component is indeed responsible for providing the nonconforming value. The second part, consisting of benchmarks and case studies, demonstrates the need for the rich contract language and validates that our implementation approach is performant with respect to time.
We describe here an implemented small programming language, called Alma-O, that augments the expressive power of imperative programming by a limited number of features inspired by the logic programming paradigm. These additions encourage declarative programming and make it a more attractive vehicle for problems that involve search. We illustrate the use of Alma-O by presenting solutions to a number of classical problems, including &agr;-&bgr; search, STRIPS planning, knapsack, and Eight Queens. These solutions are substantially simpler than their counterparts written in the imperative or in the logic programming style and can be used for different purposes without any modification. We also discuss here the implementation of Alma-O and an operational, executable, semantics of a large subset of the language.
The portable programming language (PPL) is one of a number of recently designed programming languages that enable the user to define new types by giving their representations and operations in terms of those of previously available types. Such provisions for the construction of objects of user-defined type have been discussed elsewhere; this work concerns the related problem of the external representations of such objects, both on input-output media and as written constants within the program text. We introduce an enhancement to the PPL design allowing specification of the external representations of objects of user-defined type. This extension to the PPL design means that objects of user-defined type can be read, written, and used as constants exactly as if their representations had been selected by the writer of the PPL compiler. The implementation and use of the added facilities are also discussed.
Symmetry reduction methods exploit symmetry in a system in order to efficiently verify its temporal properties. Two problems may prevent the use of symmetry reduction in practice: (1) the property to be checked may distinguish symmetric states and hence not be preserved by the symmetry, and (2) the system may exhibit little or no symmetry. In this article, we present a general framework that addresses both of these problems. We introduce "Guarded Annotated Quotient Structures" for compactly representing the state space of systems even when those are asymmetric. We then present algorithms for checking any temporal property on such representations, including non-symmetric properties.
Parallel programming involves finding the potential parallelism in an application and mapping it to the architecture at hand. Since a typical application has more potential parallelism than any single architecture can exploit effectively, programmers usually limit their focus to the parallelism that the available control constructs express easily and that the given architecture exploits efficiently. This approach produces programs that exhibit much less parallelism that exists in the application, and whose performance depends critically on the underlying hardware and software. We argue for an alternative approach based on control abstraction. Control abstraction is the process by which programmers define new control constructs, specifying constraints on statement ordering separately from an implementation of that ordering. With control abstraction programmers can define and use a rich variety of control constructs to represent an algorithm's potential parallelism. Since control abstraction separates the definition of a construct from its implementation, a construct may have several different implementations, each exploiting a different subset of the parallelism admitted by the construct. By selecting an implementation for each control construct using annotations, a programmer can vary the parallelism in a program to best exploit the underlying hardware without otherwise changing the source code. This approach produces programs that exhibit most of the potential parallelism in an algorithm, and whose performance can be tuned simply by choosing among the various implementations for the control constructs in use.
Writing concurrent applications is extremely challenging, not only in terms of producing bug-free and maintainable software, but also for enabling developer productivity. In this article we present the �minium concurrent-by-default programming language. Using �minium programmers express data dependencies rather than control flow between instructions. Dependencies are expressed using permissions, which are used by the type system to automatically parallelize the application. The �minium approach provides a modular and composable mechanism for writing concurrent applications, preventing data races in a provable way. This allows programmers to shift their attention from low-level, error-prone reasoning about thread interleaving and synchronization to focus on the core functionality of their applications. We study the semantics of �minium through ?�minium, a sound core calculus that leverages permission flow to enable concurrent-by-default execution. After discussing our prototype implementation we present several case studies of our system. Our case studies show up to 6.5X speedup on an eight-core machine when leveraging data group permissions to manage access to shared state, and more than 70% higher throughput in a Web server application.
Several related notions of the productivity are presented for functional languages with lazy evaluation. The notion of productivity captures the idea of computability, of progress of infinite-list programs. If an infinite-list program is productive, then every element of the list can be computed in finite �time.� These notions are used to study recursive list definitions, that is, lists defined by l where l = fl. Sufficient conditions are given in terms of the function f that either guarantee the productivity of the list or its unproductivity. Furthermore, a calculus is developed that can be used in verifying that lists defined by l where l< = f I are productive. The power and the usefulness of our theory are demonstrated by several nontrivial examples. Several observations are given in conclusion.
The scientific community has consistently demanded from computing machines an increase in the number of instructions executed per second. The latest increase has been achieved by duplication of arithmetic units for an array processor and the pipelining of functional units for vector processors. The high level programming languages for such machines have not benefited from the advances which have been made in programming language design and implementation techniques. A high level language is described in this paper which is appropriate for both array and vector processors and is defined without reference to the hardware of either type of machine. The syntax enables the parallel nature of a problem to be expressed in a form which can be readily exploited by these machines. This is achieved by using the data declarations to indicate the maximum extent of parallel processing and then to manipulate this, or a lesser extent, in the course of program execution. It was found to be possible to modify many of the structured programming and data structuring concepts for this type of parallel environment and to maintain the benefits of compile time and run time checking. Several special constructs and operators are also defined. The language offers to the large scale scientific computing community many of the advances which have been made in software engineering techniques while it exploits the architectural advances which have been made.
Concurrency-related errors, such as data races, are frustratingly difficult to track down and eliminate in large object-oriented programs. Traditional approaches to preventing data races rely on protecting instruction sequences with synchronization operations. Such control-centric approaches are inherently brittle, as the burden is on the programmer to ensure that all concurrently accessed memory locations are consistently protected. Data-centric synchronization is an alternative approach that offloads some of the work on the language implementation. Data-centric synchronization groups fields of objects into atomic sets to indicate that these fields must always be updated atomically. Each atomic set has associated units of work, that is, code fragments that preserve the consistency of that atomic set. Synchronization operations are added automatically by the compiler. We present an extension to the Java programming language that integrates annotations for data-centric concurrency control. The resulting language, called AJ, relies on a type system that enables separate compilation and supports atomic sets that span multiple objects and that also supports full encapsulation for more efficient code generation. We evaluate our proposal by refactoring classes from standard libraries, as well as a number of multithreaded benchmarks, to use atomic sets. Our results suggest that data-centric synchronization is easy to use and enjoys low annotation overhead, while successfully preventing data races. Moreover, experiments on the SPECjbb benchmark suggest that acceptable performance can be achieved with a modest amount of tuning.
Type constraints express subtype relationships between the types of program expressions, for example, those relationships that are required for type correctness. Type constraints were originally proposed as a convenient framework for solving type checking and type inference problems. This paper shows how type constraints can be used as the basis for practical refactoring tools. In our approach, a set of type constraints is derived from a type-correct program P. The main insight behind our work is the fact that P constitutes just one solution to this constraint system, and that alternative solutions may exist that correspond to refactored versions of P. We show how a number of refactorings for manipulating types and class hierarchies can be expressed naturally using type constraints. Several refactorings in the standard distribution of Eclipse are based on our work.
Compaction of a managed heap is a costly operation to be avoided as much as possible in commercial runtimes. Instead, partial compaction is often used to defragment parts of the heap and avoid space blowup. Previous study of compaction limitation provided some initial asymptotic bounds but no implications for practical systems. In this work, we extend the theory to obtain better bounds and make them strong enough to become meaningful for modern systems.
A simple calculus (the Director String Calculus-DSC) for expressing abstractions is introduced, which captures the essence of the �long reach� combinators introduced by Turner. We present abstraction rules that preserve the applicative structure of the original lambda term, and that cannot increase the number of subterms in the translation. A translated lambda term can be reduced according to the evaluation rules of DSC. If this terminates with a DSC normal form, this can be translated into a lambda term using rules presented below. We call this process of abstracting a lambda term, reducing to normal form in the space of DSC terms, and translating back to a lambda term an implementation. We show that our implementation of the lambda calculus is correct: For lambda terms with a normal form that contains no lambdas (ground terms), the implementation is shown to yield a lambda calculus normal form. For lambda terms whose normal forms represent functions, it is shown that the implementation yields lambda terms that are beta-convertible in zero or more steps to the normal form of the original lambda term. In this sense, our implementation involves weak reduction according to Hindley et al. [9].
There is a significant class of operations such as mapping that are common to all data structures. The goal of generic programming is to support these operations on arbitrary data types without having to recode for each new type. The pattern calculus and combinatory type system reach this goal by representing each data structure as a combination of names and a finite set of constructors. These can be used to define generic functions by pattern-matching programs in which each pattern has a different type. Evaluation is type-free. Polymorphism is captured by quantifying over type variables that represent unknown structures. A practical type inference algorithm is provided.
The Eighth International Workshop on Foundations of Object-Oriented Languages (FOOL 8) was held on January 20, 2001, colocated with the ACM Symposium on Principles of Programming Languages in London. Kathleen Fisher chaired the program committee. Six contributed papers were presented. After the workshop, extended versions of three were solicited for this special issue of TOPLAS; the two articles that were ultimately submitted were reviewed, revised, and accepted following standard TOPLAS procedures.The special issue opens with Type-Preserving Compilation of Featherweight Java by Christopher League, Zhong Shao, and Valery Trifonov. The goal of the authors is to establish a foundation for certifying compilation of Java-like class-based languages. To this end, the authors give an encoding of core Java features in a typed intermediate language suitable for use within a type-preserving compiler. Because of its intended use, the authors focus on developing an efficient encoding. They show that the type erasure of their implementation matches the standard vtable self-application semantics of message sending.The authors use Featherweight Java (FJ), which models the core features of Java, as their source language. Their translation targets a variant of F?, already implemented as part of the SML/NJ compiler, using its row polymorphism and existential and recursive types to encode FJ. The authors show that the translation from FJ to their target preserves types.In the issue's second article, More Dynamic Object Reclassification: FickleII, Sophia Drossopoulou, Ferruccio Damiani, Mariangiola Dezani-Ciancaglini, and Paola Giannini explore the issue of dynamic reclassification, by which an object changes its class membership at runtime while retaining its identity. This ability helps model real-world situations where an object has different roles over time---for example, a person who is first a student and then graduates to become a teacher.The authors focus their study on the design of a language, FickleII, which extends an imperative, typed, class-based, object-oriented language with a reclassification operation. To specify the behavior of their language, the authors give an operational semantics. They then develop a type and effect system and show that the type system is sound, in the sense that a well-typed program cannot get stuck under the operational semantics.We would like to thank our colleagues who served on the FOOL 8 program committee and those who participated in the anonymous reviewing process for TOPLAS. Their efforts contributed greatly to the quality of this special issue.
Reference-counting is traditionally considered unsuitable for multiprocessor systems. According to conventional wisdom, the update of reference slots and reference-counts requires atomic or synchronized operations. In this work we demonstrate this is not the case by presenting a novel reference-counting algorithm suitable for a multiprocessor system that does not require any synchronized operation in its write barrier (not even a compare-and-swap type of synchronization). A second novelty of this algorithm is that it allows eliminating a large fraction of the reference-count updates, thus, drastically reducing the reference-counting traditional overhead. This article includes a full proof of the algorithm showing that it is safe (does not reclaim live objects) and live (eventually reclaims all unreachable objects).We have implemented our algorithm on Sun Microsystems' Java Virtual Machine (JVM) 1.2.2 and ran it on a four-way IBM Netfinity 8500R server with 550-MHz Intel Pentium III Xeon and 2 GB of physical memory. Our results show that the algorithm has an extremely low latency and throughput that is comparable to the stop-the-world mark and sweep algorithm used in the original JVM.
MultiJava is a conservative extension of the Java programming language that adds symmetric multiple dispatch and open classes. Among other benefits, multiple dispatch provides a solution to the binary method problem. Open classes provide a solution to the extensibility problem of object-oriented programming languages, allowing the modular addition of both new types and new operations to an existing type hierarchy. This article illustrates and motivates the design of MultiJava and describes its modular static typechecking and modular compilation strategies. Although MultiJava extends Java, the key ideas of the language design are applicable to other object-oriented languages, such as C# and C++, and even, with some modifications, to functional languages such as ML.This article also discusses the variety of application domains in which MultiJava has been successfully used by others, including pervasive computing, graphical user interfaces, and compilers. MultiJava allows users to express desired programming idioms in a way that is declarative and supports static typechecking, in contrast to the tedious and type-unsafe workarounds required in Java. MultiJava also provides opportunities for new kinds of extensibility that are not easily available in Java.
We describe universal types, existential types, and type constructors in Cyclone, a strongly typed C-like language. We show how the language naturally supports first-class polymorphism and polymorphic recursion while requiring an acceptable amount of explicit type information. More importantly, we consider the soundness of type variables in the presence of C-style mutation and the address-of operator. For polymorphic references, we describe a solution more natural for the C level than the ML-style �value restriction.� For existential types, we discover and subsequently avoid a subtle unsoundness issue resulting from the address-of operator. We develop a formal abstract machine and type-safety proof that capture the essence of type variables at the C level.
Ownership is a powerful concept to structure the object store and to control aliasing and modifications of objects. This article presents an ownership type system for a Java-like programming language with generic types. Like our earlier Universe type system, Generic Universe Types structure the heap hierarchically. In contrast to earlier work, we separate the enforcement of an ownership topology from an encapsulation system. The topological system uses an existential modifier to express that no ownership information is available statically. On top of the topological system, we build an encapsulation system that enforces the owner-as-modifier discipline. This discipline does not restrict aliasing, but requires modifications of an object to be initiated by its owner. This allows owner objects to control state changes of owned objects�for instance, to maintain invariants. Separating the topological system from the encapsulation system allows for a cleaner formalization, separation of concerns, and simpler reuse of the individual systems in different contexts.
Assessing the trustworthiness of reviews is a key issue for the maintainers of opinion sites such as TripAdvisor, given the rewards that can be derived from posting false or biased reviews. In this paper we present a number of criteria that might be indicative of suspicious reviews and evaluate alternative methods for integrating these criteria to produce a unified "suspiciousness" ranking. The criteria derive from characteristics of the network of reviewers and also from analysis of the content and impact of reviews and ratings. The integration methods that are evaluated are singular value decomposition and the unsupervised hedge algorithm. These alternatives are evaluated in a user study on TripAdvisor reviews, where volunteers were asked to rate the suspiciousness of reviews that have been highlighted by the criteria.
Traditional recommendation systems use multiple computational techniques to perform personalized recommendations, and can consider the interests of users and even the context in which they live. However, they usually ignore each individual's personality factors, and hence, the recommendations generated overwhelmingly consider that all the users are identical psychologically. They ignore, for example, the curiosity level of each user, which may indicate that individuals with a high level of curiosity seek visit exotic locations and/or not yet visited by them, or even individuals with a low curiosity level tend to do the same things they did in the past, uninterested in new or different areas. Our paper presents a complete hybrid recommendation system considering the curiosity level of each individual as a decisive factor to recommend sites of South America. In order to prove the efficiency of our system in contrast to traditional recommendation systems, as well as to measure the satisfaction of users about the recommendations, we performed some preliminary experiments with the participation of 105 Brazilian volunteers. The first results indicate that considering the level of curiosity of a user increases the satisfaction with the recommendations.
Air pollution data exhibit characteristics like long range correlations and multi-fractal scaling that can be exploited to implement an energy efficient, adaptive spatial sampling technique for pollution sensor nodes. In this work, we present a) results from de-trended fluctuation analysis to prove the presence of non-linear dynamics in real pollution datasets gathered from trials carried out in Cyprus, b) a novel Multi-scale Nearest Neighbors based Adaptive Spatial Sampling (MNNASS) technique that determines the predictability and in turn the directional influences between data from different sensor nodes, and c) performance analysis of the algorithm in terms of energy savings and measurement accuracy.
A building testbed for design and evaluation of energy efficient control and demand response strategies for real buildings is presented. The testbed is a scaled down model of a centralized Heating, Ventilation and Air Conditioning (HVAC) and lighting system. Sensing and control in the tesbed is achieved using the standard Building Automation and Control Network protocol. A MATLAB based front-end can be used to run and observe experiments.
We present Squirrel, a stream-oriented programming framework for storage-centric sensor networks. The storage-centric paradigm---where storage operations prevail over communication activity---applies to scenarios such as batch data collection, delay-tolerant mobile applications, and disconnected operations in static networks. Squirrel simplifies developing such applications by decoupling data processing from storage, and by transparently handling the latter. We achieve this through: i) a modular programming abstraction, and ii) a lightweight run-time layer that efficiently allocates data to different storage areas, based on size vs. energy tradeoffs. We demonstrate Squirrel's effectiveness based on three real-world applications, each representing a different storage-centric scenario. The results show that---while relieving programmers from a significant burden---Squirrel achieves efficient utilization of storage areas, enabling energy savings independently of the storage technology.
The accurate measurement of airflow patterns at high spatial and temporal resolutions is of great importance for building design and operation. Microelectromechanical Systems (MEMS) technology can be used to develop miniaturized airflow sensors capable of detecting both airflow speed and direction at high temporal resolution. Wireless sensor networks (WSNs) are used extensively for large-scale monitoring at high spatial resolution. Thus, the integration of MEMS and WSN technologies enables the measurement of airflow patterns at high spatial and temporal resolution. In this work, we developed a prototype MEMS-based airflow sensor network and deployed it in a building environment.
Large legacy systems that have been in use for several decades need to evolve in order to take advantage of new technological advances. One such development is the emergence of multi-core processors and parallel platforms. However, the evolution of code written for single-core platforms into code that can take advantage of multi-core technology is challenging. The aim of this research is to explore the challenges that parallel programmers face in the evolution of existing software to exploit multicore and parallel architectures. A review of the current literature was conducted and ten frequently reported challenges were identified. It is important to raise awareness of potential challenges that practitioners may face when evolving sequential code to exploit multicore platforms in order to be better prepared for future evolution. The research community can use these results to develop a research agenda in order to design and develop solutions to address these challenges.
Model-driven engineering (MDE) is a software engineering discipline focusing on models as the primary artifacts in the software development process while programs are mainly generated by means of model-to-code transformations. In particular, modeling languages tailored to specific application domains promise to increase the productivity and quality of software development. Nevertheless due to e.g. evolving requirements, modeling languages and their meta-models evolve which means that existing models have to be migrated correspondingly. In our approach, such co-evolutions are specified as related graph transformations ensuring well-typed model migration results. Based on our earlier work on co-transformations, we now consider the automatic deduction of migration rule schemes from given meta-model evolution rules. Rule schemes form the basis for user customizations on a high abstraction level. A rule scheme deduction algorithm is presented and several customized migration schemes for different co-evolution examples are discussed.
Human-robot interaction in a shared workspace permits and often even requires physical contact between humans and robots. A key technology to ensure that physical human robot interaction is safe is to monitor contact forces by providing the robot with a tactile sensor as an artificial skin. This paper introduces a pressure sensitive skin that can be adapted to complex geometries and offers reliable contact measurements on the entire robot body. Equipped with integrated cushioning elements the sensitive skin can reduce the risk of dangerous injuries in physical human-robot interaction. Beside safety related functions, the sensitive skin offers touch based robot motion control which simplifies human-robot interaction.
Successful management of medications is critical to maintaining healthy and independent living for older adults. However, medication non-adherence is a common problem with a high risk for severe consequences, which can jeopardize older adults' chances to age in place. Well-designed robots assisting with medication management tasks could support older adults' independence. Design of successful robots will be enhanced through understanding concerns, attitudes, and preferences for medication assistance tasks. We assessed older adults' reactions to medication hand-off from a mobile manipulator with 12 participants (68-79 years). We identified factors that affected their attitudes toward a mobile manipulator for supporting general medication management tasks in the home. The older adults were open to robot assistance; however, their preferences varied depending on the nature of the medication management task. For instance, they preferred a robot (over a human) to remind them to take medications, but preferred human assistance for deciding what medication to take and for administering the medication. Factors such as perceptions of one's own capability and robot reliability influenced their attitudes.
Many older adults wish to remain in their own homes as they age [16]. However, challenges in performing home upkeep tasks threaten an older adult's ability to age in place. Even healthy independently living older adults experience challenges in maintaining their home [13]. Challenges with home tasks can be compensated through technology, such as home robots. However, for home robots to be adopted by older adult users, they must be designed to meet older adults' needs for assistance and the older users must be amenable to robot assistance for those needs. We conducted a needs assessment to (1) assess older adults' openness to assistance from robots; and (2) understand older adults' opinions about using an assistive robot to help around the home. We administered questionnaires and conducted structured group interviews with 21 independently living older adults (ages 65-93). The questionnaire data suggest that older adults prefer robot assistance for cleaning and fetching/organizing tasks overall. However their assistance preferences discriminated between tasks. The interview data provided insight as to why they hold such preferences. Older adults reported benefits of robot assistance (e.g., the robot compensating for limitations, saving them time and effort, completing undesirable tasks, and performing tasks at a high level of performance). Participants also reported concerns such as the robot damaging the environment, being unreliable at or incapable of doing a task, doing tasks the older adult would rather do, or taking up too much space/storage. These data, along with specific comments from participant interviews, provide the basis for preliminary recommendations for designing mobile manipulator robots to support aging in place.
This paper presents a novel calibration method for a head-mounted binocular gaze tracker that enables the human gaze point, representing the selective visual attention of the user, to be tracked in 3D space. The proposed method utilizes two calibration planes with visual marks to calculate the mapping points between a forward-looking camera and two eye-monitoring cameras in an expanded 3D spatial domain. As a result, the visually attentive point of the user can be tracked, regardless of variations in the distance from the user to the target object. The proposed method also provides a more convenient calibration procedure and more accurate results in tests than the previous method suggested by the authors. The performance is tested when varying the 3D position of an attentive object, and the experimental results are discussed.
This demonstration introduces SiCi (Smart ideas for Creative interplay) that brings a single-body robot to life by delivering a variety of contents and then fosters children's creativity and innovation in education.
Over recent years, the world has seen multiple uses for conversational agents. Chatbots has been implemented into ecommerce systems, such as Amazon Echo's Alexa [1]. Businesses and organizations like Facebook are also implementing bots into their applications. While a number of amazing chatbot platform exists, there are still difficulties in creating data-driven-systems as they large amount of data is needed for development and training. This paper we describe an advanced platform for evaluating and annotating human-chatbot interactions, its main features and goals, as well as the future plans we have for it.
This paper presents a haptic workspace control approach to the arms of a humanoid robot by using the Omega 7 haptic device as the control input device. The haptic device with small workspace is used to control the robot with 2 arm end-effectors of large workspace. This paper also puts forward an approach for users to feel the haptic feedback force when the robot end-effectors touch the virtual boundary areas for the safety consideration. The haptic device can move further but the robot arm end-effector will stop and the haptic force generated is proportional to the travel distance of the haptic device end-effectors until reaching the maximum value of force permitted by the designer. Simulation experiments are designed and implemented to test the motion performance of the arm end-effectors under control of haptic device and the generated haptic force when the virtual boundary walls are reached by the arm end-effectors.